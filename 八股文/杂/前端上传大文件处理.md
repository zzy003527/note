# 前端上传大文件处理

## 背景

- 当我们在做文件的导入功能的时候,如果导入的文件过大,可能会导所需要的时间够长,且失败后需要重新上传,我们需要前后端结合的方式解决这个问题





## 思路

- 我们需要做几件事情如下:
  - **对文件做切片**,即将一个请求拆分成多个请求，每个请求的时间就会缩短，且如果某个请求失败，只需要重新发送这一次请求即可，无需从头开始
  - **通知服务器合并切片**,在上传完切片后,前端通知服务器做合并切片操作
  - **控制多个请求的并发量**,防止多个请求同时发送,造成浏览器内存溢出,导致页面卡死
  - **做断点续传**,当多个请求中有请求发送失败,例如出现网络故障、页面关闭等,我们得对失败的请求做处理,让它们重复发送





## 实现

### 一、切片，合并切片

#### 1.1 前端实现

- 在`JavaScript中`，文件`FIle`对象是`Blob`对象的子类，`Blob`对象包含一个重要的方法`slice`通过这个方法，我们就可以对二进制文件进行拆分,具体代码如下:

  ```html
  <!DOCTYPE html>
  <html lang="en">
  <head>
      <meta charset="UTF-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=s, initial-scale=1.0">
      <title>Document</title>
      <script src="https://cdn.bootcdn.net/ajax/libs/axios/0.24.0/axios.min.js"></script>
  </head>
  <body>
      <input type="file" id="fileInput">
      <button id="uploadBtn">上传</button>
  </body>
  <script>
  // 请求基准地址
  axios.defaults.baseURL = 'http://localhost:3000'
  // 选中的文件
  var file = null
  // 选择文件
  document.getElementById('fileInput').onchange = function({target: {files}}){
      file = files[0] 
  }
  // 开始上传
  document.getElementById('uploadBtn').onclick = async function(){
      if (!file) return
      // 创建切片   
      // let size = 1024 * 1024 * 10 //10MB 切片大小
      let size = 1024 * 50  //50KB 切片大小
      let fileChunks = []
      let index = 0 //切片序号
      for(let cur = 0; cur < file.size; cur += size){
          fileChunks.push({
              hash: index++,
              chunk: file.slice(cur, cur + size)
          })
      }
      // 上传切片
      const uploadList = fileChunks.map((item, index) => {
          let formData = new FormData()
          formData.append('filename', file.name)
          formData.append('hash', item.hash)
          formData.append('chunk', item.chunk)
          return axios({
              method: 'post',
              url: '/upload',
              data: formData
          })
      })
      await Promise.all(uploadList)
      // 合并切片
      await axios({
          method: 'get',
          url: '/merge',
          params: {
              filename: file.name
          }
      });
      console.log('上传完成')
  }
  </script>
  </html>
  ```





#### 1.2 后端实现

- **安装依赖**

  - ```bash
    npm i express@4.17.2
    npm i multiparty@4.2.2
    ```

- 接口实现

  - ```js
    const express = require('express')
    const multiparty = require('multiparty')
    const fs = require('fs')
    const path = require('path')
    const { Buffer } = require('buffer')
    // 上传文件最终路径
    const STATIC_FILES = path.join(__dirname, './static/files')
    // 上传文件临时路径
    const STATIC_TEMPORARY = path.join(__dirname, './static/temporary')
    const server = express()
    // 静态文件托管
    server.use(express.static(path.join(__dirname, './dist')))
    // 切片上传的接口
    server.post('/upload', (req, res) => {
        const form = new multiparty.Form();
        form.parse(req, function(err, fields, files) {
            let filename = fields.filename[0]
            let hash = fields.hash[0]
            let chunk = files.chunk[0]
            let dir = `${STATIC_TEMPORARY}/${filename}`
            // console.log(filename, hash, chunk)
            try {
                if (!fs.existsSync(dir)) fs.mkdirSync(dir)
                const buffer = fs.readFileSync(chunk.path)
                const ws = fs.createWriteStream(`${dir}/${hash}`)
                ws.write(buffer)
                ws.close()
                res.send(`${filename}-${hash} 切片上传成功`)
            } catch (error) {
                console.error(error)
                res.status(500).send(`${filename}-${hash} 切片上传失败`)
            }
        })
    })
    //合并切片接口
    server.get('/merge', async (req, res) => {
        const { filename } = req.query
        try {
            let len = 0
            const bufferList = fs.readdirSync(`${STATIC_TEMPORARY}/${filename}`).map((hash,index) => {
                const buffer = fs.readFileSync(`${STATIC_TEMPORARY}/${filename}/${index}`)
                len += buffer.length
                return buffer
            });
            //合并文件
            const buffer = Buffer.concat(bufferList, len);
            const ws = fs.createWriteStream(`${STATIC_FILES}/${filename}`)
            ws.write(buffer);
            ws.close();
            res.send(`切片合并完成`);
        } catch (error) {
            console.error(error);
        }
    })
    
    server.listen(3000, _ => {
        console.log('http://localhost:3000/')
    })
    ```





### 二、并发控制

- 结合`Promise.race`和`异步函数`实现,多个请求同时并发的数量,防止浏览器内存溢出,具体代码如下:

  - ```html
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=s, initial-scale=1.0">
        <title>Document</title>
        <script src="https://cdn.bootcdn.net/ajax/libs/axios/0.24.0/axios.min.js"></script>
    </head>
    <body>
        <input type="file" id="fileInput">
        <button id="uploadBtn">上传</button>
    </body>
    <script>
    // 请求基准地址
    axios.defaults.baseURL = 'http://localhost:3000'
    // 选中的文件
    var file = null
    // 选择文件
    document.getElementById('fileInput').onchange = function({target: {files}}){
        file = files[0] 
    }
    // 开始上传
    document.getElementById('uploadBtn').onclick = async function(){
        if (!file) return
        // 创建切片   
        // let size = 1024 * 1024 * 10; //10MB 切片大小
        let size = 1024 * 50 //50KB 切片大小
        let fileChunks = []
        let index = 0 //切片序号
        for(let cur = 0; cur < file.size; cur += size){
            fileChunks.push({
                hash: index++,
                chunk: file.slice(cur, cur + size)
            });
        }
        // 控制并发
        let pool = []//并发池
        let max = 3 //最大并发量
        for(let i=0;i<fileChunks.length;i++){
            let item = fileChunks[i]
            let formData = new FormData()
            formData.append('filename', file.name)
            formData.append('hash', item.hash)
            formData.append('chunk', item.chunk)
            // 上传切片
            let task = axios({
                method: 'post',
                url: '/upload',
                data: formData
            })
            task.then((data)=>{
                //请求结束后将该Promise任务从并发池中移除
                let index = pool.findIndex(t=> t===task)
                pool.splice(index)
            })
            pool.push(task)
            if(pool.length === max){
                //当并发池长度达到最大并发量时，利用Promise.race的特性，等到并发池pool中有一个返回后，再进入下一轮循环塞入一个新任务
                await Promise.race(pool)
            }
        }
        //所有任务完成,合并切片
        await axios({
            method: 'get',
            url: '/merge',
            params: {
                filename: file.name
            }
        });
        console.log('上传完成')
    }
    </script>
    </html>
    ```





### 三、上传失败处理

- 在单个请求失败后,触发`catch`的方法的时候,讲当前请求放到失败列表中,在本轮请求完成后,重复对失败请求做处理,具体代码如下:

  ```html
  <!DOCTYPE html>
  <html lang="en">
  <head>
      <meta charset="UTF-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=s, initial-scale=1.0">
      <title>Document</title>
      <script src="https://cdn.bootcdn.net/ajax/libs/axios/0.24.0/axios.min.js"></script>
  </head>
  <body>
      <input type="file" id="fileInput">
      <button id="uploadBtn">上传</button>
  </body>
  <script>
  // 请求基准地址
  axios.defaults.baseURL = 'http://localhost:3000'
  // 选中的文件
  var file = null
  // 选择文件
  document.getElementById('fileInput').onchange = function({target: {files}}){
      file = files[0] 
  }
  // 开始上传
  document.getElementById('uploadBtn').onclick = function(){
      if (!file) return;
      // 创建切片   
      // let size = 1024 * 1024 * 10; //10MB 切片大小
      let size = 1024 * 50; //50KB 切片大小
      let fileChunks = [];
      let index = 0 //切片序号
      for(let cur = 0; cur < file.size; cur += size){
          fileChunks.push({
              hash: index++,
              chunk: file.slice(cur, cur + size)
          })
      }
      // 控制并发和断点续传
      const uploadFileChunks = async function(list){
          if(list.length === 0){
              //所有任务完成,合并切片
              await axios({
                  method: 'get',
                  url: '/merge',
                  params: {
                      filename: file.name
                  }
              });
              console.log('上传完成')
              return
          }
          let pool = []//并发池
          let max = 3 //最大并发量
          let finish = 0//完成的数量
          let failList = []//失败的列表
          for(let i=0;i<list.length;i++){
              let item = list[i]
              let formData = new FormData()
              formData.append('filename', file.name)
              formData.append('hash', item.hash)
              formData.append('chunk', item.chunk)
              // 上传切片
              let task = axios({
                  method: 'post',
                  url: '/upload',
                  data: formData
              })
              task.then((data)=>{
                  //请求结束后将该Promise任务从并发池中移除
                  let index = pool.findIndex(t=> t===task)
                  pool.splice(index)
              }).catch(()=>{
                  failList.push(item)
              }).finally(()=>{
                  finish++
                  //所有请求都请求完成
                  if(finish===list.length){
                      uploadFileChunks(failList)
                  }
              })
              pool.push(task)
              if(pool.length === max){
                  //每当并发池跑完一个任务，就再塞入一个任务
                  await Promise.race(pool)
              }
          }
      }
      uploadFileChunks(fileChunks)
  
  }
  </script>
  </html>
  ```





### 四、断点续传

- 断点续传的原理在于前端/服务端需要`记住`已上传的切片，这样下次上传就可以跳过之前已上传的部分，有两种方案实现记忆的功能
  - 前端使用 localStorage 记录已上传的切片 hash
  - 服务端保存已上传的切片 hash，前端每次上传前向服务端获取已上传的切片
  - 第一种是前端的解决方案，第二种是服务端，而前端方案有一个缺陷，如果换了个浏览器就失去了记忆的效果，所以这里选后者



#### 4.1 生成hash

- 无论是前端还是服务端，都必须要生成文件和切片的 hash，`之前我们使用文件名 + 切片下标作为切片 hash`，这样做文件名一旦修改就失去了效果，而事实上只要文件内容不变，hash 就不应该变化，所以正确的做法是`根据文件内容生成 hash`，所以我们修改一下 hash 的生成规则

  - 这里用到另一个库 [`spark-md5`](https://link.juejin.cn/?target=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2Fspark-md5)，它可以根据文件内容计算出文件的 hash 值
  - 另外考虑到如果上传一个超大文件，读取文件内容计算 hash 是非常耗费时间的，并且会`引起 UI 的阻塞`，导致页面假死状态，所以我们使用 `web-worker` 在 worker 线程计算 hash，这样用户仍可以在主界面正常的交互
    - 切割一个较大的文件，比如10G，那分割为1Mb大小的话，将会生成一万个切片，众所周知，js是单线程模型，如果这个计算过程在主线程中的话，那我们的页面必然会直接崩溃
    - 由于实例化 web-worker 时，参数是一个 js 文件路径且不能跨域，所以我们单独创建一个 hash.js 文件放在 public 目录下，另外在 worker 中也是不允许访问 dom 的，但它提供了`importScripts` 函数用于导入外部脚本，通过它导入 spark-md5

- ```js
  // /public/hash.js
  
  // 导入脚本
  self.importScripts("/spark-md5.min.js");
  
  // 生成文件 hash
  self.onmessage = e => {
    const { fileChunkList } = e.data;
    const spark = new self.SparkMD5.ArrayBuffer();
    let percentage = 0;
    let count = 0;
    const loadNext = index => {
      const reader = new FileReader();
      reader.readAsArrayBuffer(fileChunkList[index].file);
      reader.onload = e => {
        count++;
        spark.append(e.target.result);
        if (count === fileChunkList.length) {
          self.postMessage({
            percentage: 100,
            hash: spark.end()
          });
          self.close();
        } else {
          percentage += 100 / fileChunkList.length;
          self.postMessage({
            percentage
          });
          // calculate recursively
          loadNext(count);
        }
      };
    };
    loadNext(0);
  };
  ```

  - 在 worker 线程中，接受文件切片 fileChunkList，利用 fileReader 读取每个切片的 ArrayBuffer 并不断传入 spark-md5 中，每计算完一个切片通过 postMessage 向主线程发送一个进度事件，全部完成后将最终的 hash 发送给主线程

  

- 接着编写主线程与 worker 线程通讯的逻辑

  - ```diff
    +    // 生成文件 hash（web-worker）
    +    calculateHash(fileChunkList) {
    +      return new Promise(resolve => {
    +        // 添加 worker 属性
    +        this.container.worker = new Worker("/hash.js");
    +        this.container.worker.postMessage({ fileChunkList });
    +        this.container.worker.onmessage = e => {
    +          const { percentage, hash } = e.data;
    +          this.hashPercentage = percentage;
    +          if (hash) {
    +            resolve(hash);
    +          }
    +        };
    +      });
        },
        async handleUpload() {
          if (!this.container.file) return;
          const fileChunkList = this.createFileChunk(this.container.file);
    +     this.container.hash = await this.calculateHash(fileChunkList);
          this.data = fileChunkList.map(({ file }，index) => ({
    +       fileHash: this.container.hash,
            chunk: file,
            hash: this.container.file.name + "-" + index,
            percentage:0
          }));
          await this.uploadChunks();
        }   
    ```

  - 主线程使用 `postMessage` 给 worker 线程传入所有切片 fileChunkList，并监听 worker 线程发出的 postMessage 事件拿到文件 hash

- 服务端则使用固定前缀 + hash 作为切片文件夹名，hash + 下标作为切片名，hash + 扩展名作为文件名

  ![image-20220513232329264](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8aaec09e76c04d8c9a2bb5f3c2963070~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)







#### 4.2 文件秒传

- 所谓的文件秒传，即在服务端已经存在了上传的资源，所以当用户`再次上传`时会直接提示上传成功

- 文件秒传需要依赖上一步生成的 hash，即在`上传前`，先计算出文件 hash，并把 hash 发送给服务端进行验证，由于 hash 的唯一性，所以一旦服务端能找到 hash 相同的文件，则直接返回上传成功的信息即可

- ```diff
  +    async verifyUpload(filename, fileHash) {
  +       const { data } = await this.request({
  +         url: "http://localhost:3000/verify",
  +         headers: {
  +           "content-type": "application/json"
  +         },
  +         data: JSON.stringify({
  +           filename,
  +           fileHash
  +         })
  +       });
  +       return JSON.parse(data);
  +     },
     async handleUpload() {
        if (!this.container.file) return;
        const fileChunkList = this.createFileChunk(this.container.file);
        this.container.hash = await this.calculateHash(fileChunkList);
  +     const { shouldUpload } = await this.verifyUpload(
  +       this.container.file.name,
  +       this.container.hash
  +     );
  +     if (!shouldUpload) {
  +       this.$message.success("skip upload：file upload success");
  +       return;
  +    }
       this.data = fileChunkList.map(({ file }, index) => ({
          fileHash: this.container.hash,
          index,
          hash: this.container.hash + "-" + index,
          chunk: file,
          percentage: 0
        }));
        await this.uploadChunks();
      }   
  ```







#### 4.3 暂停上传

- 讲完了生成 hash 和文件秒传，回到断点续传

- 断点续传顾名思义即断点 + 续传，所以我们第一步先实现“断点”，也就是暂停上传

- 原理是使用 XMLHttpRequest 的 `abort` 方法，可以取消一个 xhr 请求的发送，为此我们需要将上传每个切片的 xhr 对象保存起来，我们再改造一下 request 方法

- 改造一下request方法

  ```diff
     request({
        url,
        method = "post",
        data,
        headers = {},
        onProgress = e => e,
  +     requestList
      }) {
        return new Promise(resolve => {
          const xhr = new XMLHttpRequest();
          xhr.upload.onprogress = onProgress;
          xhr.open(method, url);
          Object.keys(headers).forEach(key =>
            xhr.setRequestHeader(key, headers[key])
          );
          xhr.send(data);
          xhr.onload = e => {
  +          // 将请求成功的 xhr 从列表中删除
  +          if (requestList) {
  +            const xhrIndex = requestList.findIndex(item => item === xhr);
  +            requestList.splice(xhrIndex, 1);
  +          }
            resolve({
              data: e.target.response
            });
          };
  +        // 暴露当前 xhr 给外部
  +        requestList?.push(xhr);
        });
      },
  ```

  - 这样在上传切片时传入 requestList 数组作为参数，request 方法就会将所有的 xhr 保存在数组中了![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e6361aac2de942eba76b97814737b9ec~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
  - 每当一个切片上传成功时，将对应的 xhr 从 requestList 中删除，所以 requestList 中只保存`正在上传切片的 xhr`

- 之后新建一个暂停按钮，当点击按钮时，调用保存在 requestList 中 xhr 的 abort 方法，即取消并清空所有正在上传的切片

  - ```js
     handlePause() {
        this.requestList.forEach(xhr => xhr?.abort());
        this.requestList = [];
    }
    ```







#### 4.4 恢复上传

- 由于当文件切片上传后，服务端会建立一个文件夹存储所有上传的切片，所以每次前端上传前可以调用一个接口，服务端将已上传的切片的切片名返回，前端再跳过这些已经上传切片，这样就实现了“续传”的效果

- 而这个接口可以和之前秒传的验证接口合并，前端每次上传前发送一个验证的请求，返回两种结果

  - 服务端已存在该文件，不需要再次上传
  - 服务端不存在该文件或者已上传部分文件切片，通知前端进行上传，并把**已上传**的文件切片返回给前端

  

- 前端有两个地方需要调用验证的接口

  - 点击上传时，检查是否需要上传和已上传的切片
  - 点击暂停后的恢复上传，返回已上传的切片

  新增恢复按钮并改造原来上传切片的逻辑

  ```diff
  <template>
    <div id="app">
        <input
          type="file"
          @change="handleFileChange"
        />
         <el-button @click="handleUpload">upload</el-button>
         <el-button @click="handlePause" v-if="isPaused">pause</el-button>
  +      <el-button @click="handleResume" v-else>resume</el-button>
        //...
      </div>
  </template>
  ​
  +   async handleResume() {
  +      const { uploadedList } = await this.verifyUpload(
  +        this.container.file.name,
  +        this.container.hash
  +      );
  +      await this.uploadChunks(uploadedList);
      },
      async handleUpload() {
        if (!this.container.file) return;
        const fileChunkList = this.createFileChunk(this.container.file);
        this.container.hash = await this.calculateHash(fileChunkList);
  +     const { shouldUpload, uploadedList } = await this.verifyUpload(
  +       this.container.file.name,
  +       this.container.hash
  +     );
  +     if (!shouldUpload) {
  +       this.$message.success("skip upload：file upload success");
  +       return;
  +     }
        this.data = fileChunkList.map(({ file }, index) => ({
          fileHash: this.container.hash,
          index,
          hash: this.container.hash + "-" + index,
          chunk: file，
          percentage: 0
        }));
  +      await this.uploadChunks(uploadedList);
      },
      // 上传切片，同时过滤已上传的切片
  +   async uploadChunks(uploadedList = []) {
        const requestList = this.data
  +       .filter(({ hash }) => !uploadedList.includes(hash))
          .map(({ chunk, hash, index }) => {
            const formData = new FormData();
            formData.append("chunk", chunk);
            formData.append("hash", hash);
            formData.append("filename", this.container.file.name);
            formData.append("fileHash", this.container.hash);
            return { formData, index };
          })
          .map(({ formData, index }) =>
            this.request({
              url: "http://localhost:3000",
              data: formData,
              onProgress: this.createProgressHandler(this.data[index]),
              requestList: this.requestList
            })
          );
        await Promise.all(requestList);
  +     // 之前上传的切片数量 + 本次上传的切片数量 = 所有切片数量时合并切片
  +     if (uploadedList.length + requestList.length === this.data.length) {
           await this.mergeRequest();
  +     }
      }
  ```

  - 这里给原来上传切片的函数新增 uploadedList 参数，即上图中服务端返回的切片名列表，通过 filter 过滤掉已上传的切片，并且由于新增了已上传的部分，所以之前合并接口的触发条件做了一些改动







## 总结

- 大文件上传

  - 前端上传大文件时使用 Blob.prototype.slice 将文件切片，并发上传多个切片，最后发送一个合并的请求通知服务端合并切片

  - 服务端接收切片并存储，收到合并请求后使用流将切片合并到最终文件

  - 原生 XMLHttpRequest 的 upload.onprogress 对切片上传进度的监听

    

- 断点续传

  - 使用 spark-md5 根据文件内容算出文件 hash
  - 通过 hash 可以判断服务端是否已经上传该文件，从而直接提示用户上传成功（秒传）
  - 通过 XMLHttpRequest 的 abort 方法暂停切片的上传
  - 上传前服务端返回已经上传的切片名，前端跳过这些切片的上传

  