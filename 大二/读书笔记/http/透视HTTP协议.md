# 透视HTTP协议

## 一.破冰篇

### 1.HTTP协议基础

#### 1.1  HTTP是什么

- HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。

- HTTP 专门用来在两点之间传输数据，不能用于广播、寻址或路由。

- HTTP 传输的是文字、图片、音频、视频等超文本数据。

- HTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。

- 即：**HTTP是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范**

- 可以把HTTP定义为：与HTTP协议相关的所有应用层技术的总和

- ![image-20221018205409865](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221018205409865.png)

  ![image-20221018205435652](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221018205435652.png)

#### 1.2 与HTTP相关的各种概念

- 浏览器
  - 浏览器的正式名字叫"Web Browser"。顾名思义就是**检索、查看互联网上网页资源的应用程序**
  - 浏览器本质上是一个HTTP协议中的**请求方**，使用HTTP协议获取网络上的各种资源
- Web服务器
  - HTTP协议的**响应方**就是Web服务器
- CDN
  - 浏览器和服务器是HTTP协议的两个端点，在它们中间的一个重要角色就是CDN
  - CDN（Content Delivery Network）是"内容分发网络"。
  - 它应用了HTTP协议里的缓存和代理技术，代替源站响应客户端的请求
  - **CDN的好处：**它可以缓存源站的数据，让浏览器的请求不用"千里迢迢“找到源站服务器，而可以在"半路"就获取响应。
- 爬虫
  - 爬虫实际上**是一种可以自动访问Web资源的应用程序**
  - 爬虫是怎么来的？
    - 绝大多数是由各大搜索引擎"放"出来的，抓取网页存入数据库，再建立关键字索引，这样我们才能够再搜索引擎中快速地搜索到互联网角落中的页面
- HTML/WebService/WAF
  - **HTML**是HTTP协议传输的主要内容之一，它描述了超文本页面，用各种标签定义文字、图片等资源和排版布局，最终由浏览器"渲染"出可视化页面
  - **Web Service**是一种由W3C定义的应用服务开发规范，使用client-server主从架构，通常使用WSDL定义服务接口，使用HTTP协议传输XML或SOAP消息。也就是说它是**一个基于Web（HTTP）的服务架构技术**
  - WAF是**网络应用防火墙**。
    - 它是防护Web应用的安全技术，专门检测HTTP流量
    - WAF通常位于Web服务器之前，可以组织如SQL注入、跨站脚本等攻击
- ![image-20221018212332978](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221018212332978.png)





#### 1.3 与HTTP相关的各种协议

- TCP/IP
  - TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。
    TCP/IP 是网络世界最常用的协议，HTTP 通常运行在 TCP/IP 提供的可靠传输基础上；
  - IP（Internet Protocol，网际互连协议）
    - IP 协议的目的是解决寻址和路由问题，以及如何在两点间传送数据包。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机。
  - TCP （Transmission Control Protocol，传输控制协议）
    - TCP 协议位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。

- DNS（Domain Name System，域名系统）

  - 域名用“.”分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”。对于顶级域名，可能你随口就能说出几个，例如表示商业公司的“com”、表示教育机构的“edu”，表示国家的“cn”“uk”等。
  - 但想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，“映射”到它的真实 IP，这就是所谓的“域名解析”。

- URI/URL

  - URI（Uniform Resource Identifier，统一资源标识符）

    - 能够唯一地标记互联网上资源

      ```js
      http://nginx.org/en/download.html
      ```

    - URI 主要有三个基本的部分构成：

      - 协议名：即访问该资源应当使用的协议，在这里是“http”；
      - 主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”；
      - 路径：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”。

  - URL（Uniform Resource Locator，统一资源定位符）

    - 是我们俗称的“网址”，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分。

- HTTPS（HTTP over SSL/TLS，超文本传输安全协议）

  - HTTPS是以安全为目标的 HTTP 通道，**在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性** 。HTTPS 在HTTP 的基础下加入SSL，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP与 TCP 之间）。这个系统提供了身份验证与加密通讯方法。

- Proxy（代理）

  - **代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。**
  - 代理有很多的种类，常见的有：
    - 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；
    - 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；
    - 正向代理：靠近客户端，代表客户端向服务器发送请求；
    - 反向代理：靠近服务器端，代表服务器响应客户端的请求；





#### 1.4 网络分层模型

- TCP/IP网络分层模型
  - TCP/IP协议共有四层，从下往上依次是：
    - 第一层：**链接层**
      - 负责在以太网、WIFI这样的底层网络上发送原始数据包，工作在网卡这个层次，使用MAC地址来标记网络上的设备，所以有时候也叫MAC层
    - 第二层：**网际层**或**网络互连层**
      - IP协议就处在这一层
      - 因为IP协议定义了"IP地址"的概念，所以就可以用IP地址取代MAC地址，把许许多多的局域网、广域网连接成一个巨大网络，在这个网络里找设备时只需要把IP地址再"翻译"为MAC地址即可
    - 第三层：**传输层**
      - 这个层次协议的职责是保证数据在IP地址标记的两点之间"可靠"地传输，是TCP协议工作的层次
    - 第四层：**应用层**
      - 这一层由各种面向具体应用的协议，如：Telnet、SSH、FTP、SMTP、HTTP等等
- OSI网络分层模型
  - OSI，全称是"开放式系统互联通信参考模型"
  - OSI模型分为七层，从下到上分别是：
    - 第一层：物理层，网络的物理形式，例如电路、光纤、网卡、集线器等
    - 第二层：数据链路层，它基本相当于TCP/IP的链接层
    - 第三层：网络层，相当于TCP/IP中的网际层
    - 第四层：传输层，相当于TCP/IP中的传输层
    - 第五层：会话层，维护网络中的连接状态，即保持会话和同步
    - 第六层：表示层，把数据转换为合适、可理解的语法和语义
    - 第七层：应用层，面向具体的应用传输数据
- 所谓的"四层负载均衡"，就是指工作在传输层上，基于TCP/IP协议的特性，例如IP地址、端口号等实现对后端服务器的负载均衡
- 所谓的"七层负载均衡"，就是在工作在应用层上，看到的是HTTP协议，解析HTTP报文里的URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器
- TCP/IP协议栈的工作方式
  - **HTTP利用TCP/IP协议栈逐层打包再拆包，实现了数据传输，但下面的细节并不可见**
- 有一个辨别四层和七层较好的（但不是绝对的）小窍门，**两个凡是**：
  - **凡是由操作系统负责处理的就是四层或四层以下**
  - **凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层**
- 知识点：
  - 二层转发：设备工作在链路层，帧在经过交换机设备时，检查帧的头部信息，拿到目标MAC地址，进行本地转发和广播
  - 三层路由：设备工作在ip层，报文经过有路由功能的设备时，设备分析报文中的头部信息，拿到ip地址，根据网段范围，进行本地转发或选择下一个网关





#### 1.5 域名

- 域名的形式

  - 域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。最左边的是主机名，通常用来表明主机的用途
    - 例如：极客时间的域名“time.geekbang.org”，这里的“org”就是顶级域名，“geekbang”是二级域名，“time”则是主机名。使用这个域名，DNS 就会把它转换成相应的 IP 地址，你就可以访问极客时间的网站了。

- 域名的解析

  - **就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析”**

  - DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：

    1、根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；

    2、顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；

    3、权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址

  - 有了这个系统以后，任何一个域名都可以在这个树形结构里从顶至下进行查询，就好像是把域名从右到左顺序走了一遍，最终就获得了域名对应的 IP 地址。例如，你要访问“www.apple.com”，就要进行下面的三次查询：访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。

- 域名解析的过程使用两种域名查询方式

  - **递归查询**
    - 主机想知道y.abc.com的IP地址，查询信息会依次**采用递归查询**传到本地域名服务器，根域名服务器，顶级域名服务器，权限域名服务器，查询到结果后依次返回
  - **迭代查询**
    - 主机想知道y.abc.com的IP地址，主机首先向其本地域名服务器进行递归查询
      - 本地域名服务器采用迭代查询，它先向某个根域名服务区查询
      - 根域名服务器告诉本地域名服务器，下一次应查询的顶级域名服务器的IP地址。本地域名服务器向顶级域名服务器进行迭代查询
      - 顶级域名服务器告诉本地域名服务器，下一次应查询的权限域名服务器的IP地址。本地域名服务器向权限域名服务器进行迭代查询
      - 顶级域名服务器告诉本地域名服务器所查询的域名的IP地址。
      - 本地域名服务器最后把查询结果告诉主机
  - **由于递归查询对于被查询的域名服务器负担太大，通常采用以下模式：从请求主机到本地域名服务器的查询是递归查询，而其余的查询是迭代查询**
  - 总结：
    - 递归就是你交给别人，让别人查到，在返回给你
    - 迭代就是你找别人要，他叫你去别的地方找

- 为了提高DNS的查询效率，并减轻根域名服务器的负荷和减少因特网上的DNS查询报文数量，在域名服务器和主机中广泛地使用了**高速缓存**

  - **高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录**
  - 由于域名到IP地址的映射关系并不是永久不变，为保持高速缓存中的内容正确，域名服务器**应为每项内容设置计时器并删除超过合理时间的项**（例如，每个项目只存放两天）
  - 不但在本地域名服务器中需要高速缓存，在用户主机中也很需要。**许多用户主机在启动时从本地域名服务器下载域名和IP地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到域名时才向域名服务器查询**。同理，主机也需要保持高速缓存中内容的正确性

- 问题：

  - 在浏览器地址栏里随便输入一个不存在的域名，比如就叫“www. 不存在.com”，试着解释一下它的 DNS 解析过程
    1. 检查浏览器缓存是否存在解析"www.不存在.com"域名的ip
    2. 检查操作系统dnscache是否存在解析"www.不存在.com"域名的ip
    3. 如果没有找到继续查找本地hosts文件内是否有对应的固定记录
    4. 如果hosts中还是没有那就根据本地网卡被分配的 dns server ip 来进行解析，dns server ip 一般是“非官方”的ip，比如谷歌的“8.8.8.8”，本身它也会对查找的域名解析结果进行缓存，如果它没有缓存或者缓存失效，则先去顶级域名服务器“com”去查找“不存在.com”的域名服务器ip，结果发现不存在，于是直接返回告诉浏览器域名解析错误，当然这两次查找过程是基于udp协议







### 2.搭建HTTP实验环境（Windows环境下）

#### 2.1 软件准备

- Wireshark
  Wireshark 是著名的网络抓包工具，能够截获在 TCP/IP 协议栈中传输的所有流量，并按协议类型、地址、端口等任意过滤，功能非常强大，是学习网络协议的必备工具。
- Chrome/Firefox
  Chrome 是 Google 开发的浏览器，是目前的主流浏览器之一。它不仅上网方便，也是一个很好的调试器，对 HTTP/1.1、HTTPS、HTTP/2、QUIC 等的协议都支持得非常好，用 F12 打开“开发者工具”还可以非常详细地观测 HTTP 传输全过程的各种数据。
- Telnet
  Telnet 是一个经典的虚拟终端，基于 TCP 协议远程登录主机，我们可以使用它来模拟浏览器的行为，连接服务器后手动发送 HTTP 请求，把浏览器的干扰也彻底排除，能够从最原始的层面去研究 HTTP 协议。
- OpenResty
  OpenResty是基于 Nginx 的一个“强化包”，里面除了 Nginx 还有一大堆有用的功能模块，不仅支持 HTTP/HTTPS，还特别集成了脚本语言 Lua 简化 Nginx 二次开发，方便快速地搭建动态网关，更能够当成应用容器来编写业务逻辑。





#### 2.2 环境搭建

- 首先到github上的http_study项目下载并解压，得到：

  - ![image-20221019145254894](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221019145254894.png)

  

- **Telnet**

  - 打开Windows的设置窗口，搜索"Telnet"，然后打勾

  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518155305947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    

- **配置文件**

  - 修改本机的 hosts 文件，位置在“C:\WINDOWS\system32\drivers\etc”里面，在里面添加三行本机 IP 地址到测试域名的映射。

  - ```js
    127.0.0.1       www.chrono.com
    127.0.0.1       www.metroid.net
    127.0.0.1       origin.io
    ```

- **Wireshark安装**

  - 首先安装环回适配器。

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171021106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171026947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171032119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171036175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171128733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518171245243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

      

  - 安装npcap-1.31

    - ```js
      下载地址
      https://nmap.org/download.html
      ```

  - Wireshark-win64-3.4.5

    - ```js
      https://www.wireshark.org/download.html
      ```

  - 安装OpenResty

    - ```js
      http://openresty.org/cn/download.html
      ```

    - **注意：要把压缩包解压到刚才下载的项目中，并改名为openresty**

    

- 测试验证

  - 在http_study的"www"目录下有四个批处理文件，分别是
    - start：启动OpenResty服务器
    - stop：停止OpenResty服务器
    - reload：重启OpenResty服务器
    - list：列出已经启动的OpenResty服务器进程

  - 使用鼠标双击"start"批处理文件，就会启动OpenResty服务器在后台运行，这个过程可能会有Windows防火墙的经过，选择"允许"即可
  - 允许后，鼠标双击"list"可以查看OpenResty是否已经正常启动，应该会有两个nginx.exe的后台进程
  - 有了Web服务器后，接下来要允许Wireshark，开始抓包
    - 打开Wireshark.exe
    - 因为我们的实验环境运行在本机的127.0.0.1上，也就是loopback"环回"地址。所以，在Wireshark里要选择`Npcap loopback Adapter`，过滤器选择`HTTP TCP port（80）`，即只要抓取HTTP相关的数据报
    - 鼠标双击界面里的"Npcap loopback Adapter"即可开始抓取本机上的网络数据

  - 然后打开Chrome，在地址栏输入`http://localhost/`，访问刚才启动的OpenResty服务器，就会看到一个简单的欢迎界面
    - `Welcome to HTTP Study Page`

  - 这时回去看Wireshark，就可以看到一些数据了
  - **最后要去运行批处理"stop"停止OpenResty服务器**










## 二.基础篇

### 1.按下网址再按下回车，后面究竟发生了什么

- 使用IP地址访问Web服务器

  - 首先**运行www目录下的"start"批处理程序**，启动本机的OpenResty服务器，启动后可以**用"list"批处理确认服务是否正常运行**

  - 然后打开Wireshark，选择`HTTP TCP port(80)`过滤器，再鼠标双击"Npcap loopback Adapter"，开始抓取本机127.0.0.1地址上的网络数据

  - 在Chrome浏览器的地址栏里输入"http://127.0.0.1/"，再按下回车键，等欢迎页面显示出来后Wireshark里就会有捕获的数据包

  - 抓包分析

    - ![image-20221019163837678](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221019163837678.png)
    - **简要叙述这次最简单的浏览器HTTP请求过程：**
      - **浏览器从地址栏的输入中获得服务器的 IP 地址和端口号；**
      - **浏览器用 TCP 的三次握手与服务器建立连接；**
      - **浏览器向服务器发送拼好的报文；**
      - **服务器收到报文后处理请求，同样拼好报文再发给浏览器；**
      - **浏览器解析报文，渲染输出页面。**

    

- 使用域名访问Web服务器

  - 上面是直接输入IP地址，但是如果使用的是域名呢？

  - 我们将输入改为：`http://www.Chrono.com`

    - 显示的跟上面一样
    - Wireshark抓包过程也跟上面一样
    - 那么：**浏览器是如何从网址里知道"www.Chrono.com"的IP地址就是"127.0.0.1"呢？**

  - 在域名解析的过程中

    - 浏览器首先查看自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件hosts，也就是上一讲中我们修改的"C:\WINDOWS\system32\drivers\etc\hosts"
    - 刚好，里面有一行映射关系 “127.0.0.1  www.Chrono.com"，于是浏览器就知道了域名对应的IP地址，就可以建立TCP连接发送HTTP请求了
    - ![image-20221019164734024](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221019164734024.png)

    

- 小结：

  - HTTP协议基于底层的TCP/IP协议，所以必须要用IP地址建立连接
  - 如果不知道IP地址，就要用DNS协议去解析得到IP地址，否则就会连接失败
  - 建立TCP连接后会顺序收发数据，请求方和应答方都必须依据HTTP规范构建和解析报文
  - 为了减少响应时间，整个过程中的每一个环节都会有缓存，能够实现"短路"操作
  - 虽然现实中的HTTP传输过程非常复杂，但理论上仍然可以简化成实验里的"两点"模型







### 2.HTTP报文

- HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：
  - 起始行（start line）：描述请求或响应的基本信息；
  - 头部字段集合（header）：使用 key-value 形式更详细地说明报文；
  - 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。
  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518202406854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)



#### 2.1  报文结构

- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518175516230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)
- **HTTP 协议规定报文必须有 header，但可以没有 body，而且在 header 之后必须要有一个“空行”**，也就是“CRLF”，十六进制的“0D0A”。
  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518202717977.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)
  - 第一行“GET / HTTP/1.1”就是请求行，而后面的“Host”“Connection”等等都属于 header，报文的最后是一个空白行结束，没有 body。
  - 浏览器发送 GET 请求的时候都是这样，HTTP 报文经常是只有 header 而没 body，相当于只发了一个超级“大头”过来





#### 2.2 请求行

- **请求行由三部分构成**：

  1. **请求方法**：是一个动词，如 GET/POST，表示对资源的操作；
  2. **请求目标**：通常是一个 URI，标记了请求方法要操作的资源；
  3. **版本号**：表示报文使用的 HTTP 协议版本。

- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518202825476.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

- ```js
  GET / HTTP/1.1
  ```

  - 在这个请求行里，“GET”是请求方法，“/”是请求目标，“HTTP/1.1”是版本号，把这三部分连起来，意思就是“服务器你好，我想获取网站根目录下的默认文件，我用的协议版本号是 1.1，请不要用 1.0 或者 2.0 回复我。”





#### 2.3 状态行

- 看完了请求行，我们再看响应报文里的起始行，在这里它不叫“响应行”，而是叫“状态行”（status line），意思是**服务器响应的状态**。
  状态行要简单一些，同样**也是由三部分构成**：	

  - **版本号**：表示报文使用的 HTTP 协议版本；

  - **状态码**：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误；

  - **原因**：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518203252338.png)

- ```js
  HTTP/1.1 200 OK
  ```

  - 意思就是：“浏览器你好，我已经处理完了你的请求，这个报文使用的协议版本号是 1.1，状态码是 200，一切 OK。”

- ```js
  HTTP/1.1 404 Not Found
  ```

  - 抱歉啊浏览器，刚才你的请求收到了，但我没找到你要的资源，错误代码是 404，接下来的事情你就看着办吧





#### 2.4 头部字段

- 请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头。请求头和响应头的结构是基本一样的，唯一的区别是起始行。

- 请求

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518203933181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

- 响应

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518203939582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)

- 使用头字段需要注意下面几点：

  - 字段名不区分大小写
  - 字段名里不允许出现空格，可以使用连字符"-"，但不能使用下划线"_"
  - 字段名后面必须紧跟着":"，不能有空格；而":"后的字段值前面可以有多个空格
  - 字段的顺序是没有意义的，可以任意排列不影响语义
  - 字段原则上不能重复，除非这个字段本身的语义允许，例如Set-Cookie





#### 2.5 常用头字段

- HTTP 协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：
  - 通用字段：在请求头和响应头里都可以出现；
  - 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；
  - 响应字段：仅能出现在响应头里，补充说明响应报文的信息；
  - 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。
- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518204659190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)
  - **Host**
    - **是请求字段**，只能出现在请求头里。它同时也是唯一一个HTTP/1.规范里要求**必须出现**的字段
    - 也就是说，**如果请求头里没有host，那这就是一个错误的报文**
    - Host字段告诉服务器：这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用Host字段来选择，有点像一个简单的"路由重定向"
  - **User-Agent**
    - **User-Agent 是请求字段**，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。
  - **Date**
    - **是一个通用字段**，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。
  - **Server**
    - **Server 字段是响应字段**，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号。
  - **Content-Length**
    - 它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。







### 3.应该如何理解请求方法

#### 3.1 标准请求方法

- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518205544670.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)





#### 3.2 HTTP/1.1规定的八种方法

- 目前 HTTP/1.1 规定了八种方法，单词都必须是大写的形式
- **GET**
  - **它的含义是请求从服务器获取资源**，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据。
    GET 方法虽然基本动作比较简单，但搭配 URI 和其他头字段就能实现对资源更精细的操作。
- **HEAD**
  - **HEAD 方法与 GET 方法类似，也是请求从服务器获取资源**，服务器的处理机制也是一样的，但**服务器不会返回请求的实体数据，只会传回响应头**，也就是资源的“元信息”。
    **HEAD 方法可以看做是 GET 方法的一个“简化版”或者“轻量版”**。因为它的响应头与 GET 完全相同，所以可以用在很多并不真正需要资源的场合，避免传输 body 数据的浪费。
- **POST**
  - POST 也是一个经常用到的请求方法，使用频率应该是仅次于 GET，应用的场景也非常多，**只要向服务器发送数据，用的大多数都是 POST。**
- **PUT**
  - PUT 的作用与 POST 类似，也可以向服务器提交数据，但与 POST 存在微妙的不同，通**常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义。**
    在实际应用中，PUT 用到的比较少。而且，因为它与 POST 的语义、功能太过近似，有的服务器甚至就直接禁止使用 PUT 方法，只用 POST 方法上传数据。
- **DELETE**
  - **DELETE 方法指示服务器删除资源**，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。
- **CONNECT**
  - CONNECT 是一个比较特殊的方法，**要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。**
- **OPTIONS**
  - **OPTIONS 方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回**。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持。
- **TRACE**
  - **TRACE 方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径**。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用。







### 4.正确的网址是什么样子的

- 严格地说，URI 不完全等同于网址，它包含有 URL 和 URN 两个部分，在 HTTP 世界里用的网址实际上是 URL——统一资源定位符（Uniform Resource Locator）。但因为 URL 实在是太普及了，所以常常把这两者简单地视为相等。

#### 4.1 URI的格式

- URI 本质上是一个字符串，这个字符串的作用是唯一地标记资源的位置或者名字。
- 它由scheme、host：port、path和query四部分组成，但有的部分可以视情况省略
- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210518211147205.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MTczNjUw,size_16,color_FFFFFF,t_70)





#### 4.2 URI的基本组成

- **scheme**
  - **URI 第一个组成部分叫 scheme，翻译成中文叫“方案名”或者“协议名”，表示资源应该使用哪种协议来访问。**
- **": //"**
  - 在 scheme 之后，必须是三个特定的字符“: //”，它把 scheme 和后面的部分分离开。
    该符号无意义，只是当初设计的是这样，现在也就是这样了。
- **authority（资源所在的主机名，通常形式为host:port）**
  - 主机名可以是 IP 地址或者域名的形式，必须要有，否则浏览器就会找不到服务器。
  - 但端口号有时可以省略，浏览器等客户端会依据 scheme 使用默认的端口号，例如 HTTP 的默认端口号是 80，HTTPS 的默认端口号是 443。有了协议名和主机地址、端口号，再加上后面标记资源所在位置的 path，浏览器就可以连接服务器访问资源了。
- **path**
  - **URI的path部分必须以"/"开始，也就是必须包含"/"，不要把"/"误认为属于前面的authority**
- **URI的查询参数**
  - 使用**“协议名 + 主机名 + 路径”**的方式，已经可以精确定位网络上的任何资源了。但这还不够，很多时候我们还想在操作资源的时候附加一些额外的修饰参数。
  - 仅用“协议名 + 主机名 + 路径”的方式是无法适应这些场景的，所以 **URI 后面还有一个“query”部分，它在 path 之后，用一个<u>“?”</u>开始，但不包含“?”，表示对资源附加的额外要求**。这是个很形象的符号，比“: //”要好的多，很明显地表示了“查询”的含义。
  - 查询参数query是多个"key=value"的字符串，这些值用字符**"&"**连接





#### 4.3 URI的完整格式

- ![image-20221019191731538](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221019191731538.png)
- 这个完整格式比基本形态多了两部分：
  - 第一个多出的部分是协议名之后，主机名之前的**身份信息**"user：passwd@"，标识登录主机时的用户名和密码，但现在已经不推荐使用这种格式了，因为它把敏感信息以明文形式暴露出来，存在严重的安全隐患
  - 第二个多出的部分是查询参数后的**片段标识符**"`#fragment"`，它是URI所定位的资源内部的一个"锚点"或者说是"标签"，浏览器可以在获取资源后直接跳转到它指示的位置



#### 4.4 URI的编码

- 在 URI 里只能使用 ASCII 码,如果要在 URI 里使用英语以外的汉语、日语等其他语言,需要进行**转义**操作。
- **URI转义规则：**
  - **直接把非ASCII码或特殊字符转换成十六进制字节值，然后前面再加上一个"%"**







### 5.响应状态码该怎么用

- 状态码
  - 目前的RFC标准里规定状态码是三位数，取值范围从100~599，用数字第一位表示分类，共五类，这五类具体含义是：
    - **1XX ：提示信息，表示目前是协议处理的中间状态，還需要后续的操作；**
    - **2XX ：成功，报文已经收到并被正确处理；**
    - **3XX ：重定向，资源位置发生变动，需要客户端重新发送请求；**
    - **4XX ：客户端错误，请求报文有误，服务器无法处理；**
    - **5XX ：服务器错误，服务器在处理请求时内部发生了错误。**
- **1xx**
  - **此类属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。**
  - 101 Swiching Protocols 意思是客户端使用Upgrade头字段，要求在HTTP协议基础上改成其他协议继续通信，比如WebSocket，如果服务器统一变更协议，就会返回101，后续数据传输就不会再使用HTTP了。
- **2xx**
  - **此类表示服务器收到并成功处理了客户端的请求，客户端最喜欢的状态码。**
  - **200** ok 浏览器最喜欢的成功了；
  - 202 Accepted 浏览器收到请求，但暂缓处理，暂时无法给出处理结果；
  - **204** No Content 含义与200 OK基本相同，但响应头后没有body数据；
  - **206** Particl Content 意思是服务器成功处理了请求，但body里的数据不是资源的全部，而是一部分，这个是HTTP分块下载或断点续传的基础，在客户端放松了“范围请求”、要求获取资源的部分数据时出现。一般206后会跟着头字段“Content-Range”，表示body里数据的具体范围，例如“Content-Range：bytes 0-99/2000”。
- **3xx**
  - **此类表示客户端请求的资源发生了改动，客户端必须用新的URI创新发送请求获取资源，也就是通常所说的”重定向“**，包括注明的301、302跳转。
  - **301 Moved Permanently 俗称“永久重定向”**，含义是此次请求的资源已经不存在了，需要该用新的URI再次访问。
  - **302 Found 俗称“临时重定向”**，意思是请求的资源还在，但需要暂时用了另一个URI来访问。
  - **304 Not Modified 即“缓存重定向”**，用于If-Modified-Since等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义。可以理解成”**重定向到已缓存的文件**”
- **4xx**
  - **此类表示客户端发送的请求报文有无，服务器无法处理，含义就是“错误码”。**
  - **400** Bad Request 含义就是数据格式有误，具体哪里错误没有明说，会让客户端一头雾水，开发WEB应用时应该尽量避免；
  - **403** Forbidden 这个不是客户的的请求出错，而是服务器禁止访问资源。原因多种多样，可能是信息敏感、法律禁止等；
  - **404** Not Found 被滥用的状态码，愿意是请求的资源在服务器上找不到，但很多服务器动不动就给你来个404；
  - 405 Method Not Allowed 不允许使用某些方法操作资源，例如不允许POST只允许GET;
  - 406 Not Acceptable 资源无法满足客户端请求的条件，例如请求中文但只有英文；
  - 408 Request Timeout 请求超时，服务器等待了过长的时间；
  - 409 Conflict 多个请求发生了冲突，可以理解为多线程并发时的竞争状态；
  - 413 Request Enitity Too Large 请求报文里的body太大；
  - 414 Request-URI Too Long 请求行里的URI太长；
  - 429 Too Many Requests 客户端发送了太多请求，通常是由于服务器的限制连接策略；
  - 431 Request Header Fields Too Large 请求头某个字段或总体太大。
- **5xx**
  - **此类表示客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据，是服务器端的“错误码”。**
  - **500** Internal Server Error 相当于服务器端的400,属于通用错误码，不利于调试，但能够防止黑客窥探或分析；
  - **501** Not Implemented 表示客户端请求的功能还不支持；
  - **502** Bad Gateway 通常是服务器作为王冠或者代理是返回的错误码，表示服务器自身工作正常，访问后端服务器时发生错误，具体错误原因未知；
  - **503** Service Unavailable 服务器繁忙，当前不可用，这是一个临时的状态，通常503的响应报文里会有一个“Retry-After”字段，意思是多久后再重试。 





### 6.HTTP的优点和缺点

- **灵活可扩展**
  - **HTTP 协议是一个“灵活可扩展”的传输协议。**
  - HTTP 协议最初诞生的时候就比较简单，本着开放的精神只规定了报文的基本格式，比如用空格分隔单词，用换行分隔字段，“header+body”等，报文里的各个组成部分都没有做严格的语法语义限制，可以由开发者任意定制。
- **可靠传输**
  - **HTTP 协议是一个“可靠”的传输协议。**
  - 这个特点显而易见，因为 HTTP 协议是基于 TCP/IP 的，而 TCP 本身是一个“可靠”的传输协议，所以 HTTP 自然也就继承了这个特性，能够在请求方和应答方之间“可靠”地传输数据。
  - HTTP 并不能 100% 保证数据一定能够发送到另一端，在网络繁忙、连接质量差等恶劣的环境下，也有可能收发失败。“可靠”只是向使用者提供了一个“承诺”，会在下层用多种手段“尽量”保证数据的完整送达。
- **应用层协议**
  - HTTP 协议是一个应用层的协议
  - HTTP 凭借着可携带任意头字段和实体数据的报文结构，以及连接控制、缓存代理等方便易用的特性，一出现就“技压群雄”，迅速成为了应用层里的“明星”协议。只要不太苛求性能，HTTP 几乎可以传递一切东西，满足各种需求，称得上是一个“万能”的协议。
- **请求 - 应答**
  - HTTP 协议使用的是请求 - 应答通信模式。
  - 这个请求 - 应答模式是 HTTP 协议最根本的通信模型，通俗来讲就是**“一发一收”“有来有去”**，就像是写代码时的函数调用，只要填好请求头里的字段，“调用”后就会收到答复。请求 - 应答模式也明确了 HTTP 协议里通信双方的定位，永远是请求方先发起连接和请求，是主动的，而应答方只有在收到请求后才能答复，是被动的，如果没有请求时不会有任何动作。
- **无状态**
  - HTTP 协议是无状态的。
  - “状态”其实就是客户端或者服务器里保存的一些数据或者标志，记录了通信过程中的一些变化信息。
  - TCP 协议是有状态的，一开始处于 CLOSED 状态，连接成功后是 ESTABLISHED 状态，断开连接后是 FIN-WAIT 状态，最后又是 CLOSED 状态。
  - 这些“状态”就需要 TCP 在内部用一些数据结构去维护，可以简单地想象成是个标志量，标记当前所处的状态，例如 0 是 CLOSED，2 是 ESTABLISHED 等等。
  - 再来看 HTTP，那么对比一下 TCP 就看出来了，**在整个协议里没有规定任何的“状态”，客户端和服务器永远是处在一种“无知”的状态。**建立连接前两者互不知情，每次收发的报文也都是互相独立的，没有任何的联系。收发报文也不会对客户端或服务器产生任何影响，连接后也不会要求保存任何信息。
- 其他特点
  - HTTP 协议还可以列出非常多的特点，例如传输的实体数据可缓存可压缩、可分段获取数据、支持身份认证、支持国际化语言等。但这些并不能算是 HTTP 的基本特点，因为这都是由第一个“灵活可扩展”的特点所衍生出来的。











## 三.进阶篇

### 1.HTTP的实体数据

#### 1.1 数据类型和编码

- 在 TCP/IP 协议栈里，传输数据基本上都是“header+body”的格式。但 TCP、UDP 因为是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。
- HTTP 协议则不同，它是应用层的协议，数据到达之后工作只能说是完成了一半，还必须要告诉上层应用这是什么数据才行，否则上层应用就会“不知所措”。
- **MIME type**
  - MIME 是一个很大的标准规范，但 HTTP 只“顺手牵羊”取了其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的“MIME type”。
  - **HTTP 里经常遇到的几个类别：**
    - text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本text/plain、样式表 text/css 等。
    - image：即图像文件，有 image/gif、image/jpeg、image/png 等。
    - audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
    - application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有application/json，application/javascript、application/pdf等，另外，如果实在是不知道数据是什么类型，像刚才说的“黑盒”，就会是application/octet-stream，即不透明的二进制数据。
- **Encoding type**
  - HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续“猜”，**还需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。**
  - Encoding type 常用的只有下面三种：
    - gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
    - deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
    - br：一种专门为 HTTP 优化的新压缩算法（Brotli）。





#### 1.2 数据类型使用的头字段

- **HTTP 协议为此定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”。**也就是说，**客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。**

- **Accept**

  - **Accept 字段标记的是客户端可理解的 MIME type**，可以**用“,”做分隔符**列出多个类型，让服务器有更多的选择余地。

  - ```js
    Accept: text/html,application/xml,image/webp,image/png
    ```

  - 
    这就是告诉服务器：“我能够看懂 HTML、XML 的文本，还有 webp 和 png 的图片，请给我这四类格式的数据”。

- **Accept-Encoding**

  - **Accept-Encoding 字段标记的是客户端支持的压缩格式**，例如上面说的 gzip、deflate 等，同样也可以**用“,”列出多个**，服务器可以选择其中一种来压缩数据，实际使用的压缩格式放在响应头字段 Content-Encoding 里





#### 1.3 语言类型与编码

- 语言国际化问题
  MIME type 和 Encoding type 解决了计算机理解 body 数据的问题，但互联网遍布全球，不同国家不同地区的人使用了很多不同的语言，虽然都是 text/html，但需要显示不同的语言文字。

  - 所以在需要明确区分的时候也要使用"type-subtype"的形式，不过，**分隔符不是"/"，而是"-"**
  - 如：
    - en表示任意的英语
    - en-US表示美式英语
    - en-GB表示英式英语
    - zh-CN表示汉语

- **语言类型使用的头字段**

  - **HTTP 协议也使用 Accept 请求头字段和 Content 实体头字段，用于客户端和服务器就语言与编码进行“内容协商”。**

  - **Accept-Language**

    - **Accept-Language 字段标记了客户端可理解的自然语言**，也允许用“,”做分隔符列出多个类型，例如：

    ```js
    Accept-Language: zh-CN, zh, en
    ```

    - 这个请求头会告诉服务器：“最好给我 zh-CN 的汉语文字，如果没有就用其他的汉语方言，如果还没有就给英文”。

  - **Content-Language**

    - **服务器应该在响应报文里用头字段 Content-Language 告诉客户端<u>实体数据使用的实际语言类型</u>**：

      ```js
      Content-Language: zh-CN
      ```

  - **Accept-Charset**

    - **客户端向服务器发送的请求字符集**

  - **Content-Type**

    - **服务器向客户端发送的响应字符集类型**

    - 例如：浏览器请求GBK或UTF-8的字符集，然后服务器返回的是URF-8编码，就是这样：

      ```js
      Accept-Charset: gbk, utf-8
      Content-Type: text/html; charset=utf-8
      ```

  - 不过现在的浏览器都支持多种字符集，通常不会发送 Accept-Charset，而服务器也不会发送 Content-Language，因为使用的语言完全可以由字符集推断出来，**所以在请求头里一般只会有 Accept-Language 字段，响应头里只会有 Content-Type 字段。**

  - ![image-20221020212935230](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221020212935230.png)





#### 1.4 内容协商

- 内容协商的质量值

  - 在HTTP协议里使用Accept、Accep-Encoding、Accept-Language等请求头字段进行内容协商的时候，**还可以用一种特殊的"q"参数表示权重来设定优先级**。

  - 权重的**最大值是1，最小值是0.01，默认值是0，如果值是0就表示拒绝**。

    - 具体的形式是在数据类型或语言代码**后面加一个";"，然后是"q=value"**

  - 如：

    - ```js
      Accept: text/html,application/xml;q=0.9,*/*;q=0.8
      ```

    - 它表示浏览器最希望使用的是HTML文件，权重是1；其次是XML文件，权重是0.9；最后是任意数据类型，权重是0.8.

    - 服务器收到请求头后，就会计算权重，再根据自己的实际情况优先输出HTML或者XML

- 内容协商的结果

  - 内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个 Vary 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：

    ```js
    Vary: Accept-Encoding,User-Agent,Accept
    //这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文。
    ```









### 2.HTTP传输大文件的方法

#### 2.1 数据压缩(适用于传输文本文件)

- **通常浏览器在发送请求时都会带着“Accept-Encoding”头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进“Content-Encoding”响应头里，再把原数据压缩后发给浏览器。**
- 不过这个解决方法也有个缺点，gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了。







#### 2.2 分块传输

- 如果大文件整体不能变小，那就把它“拆开”，分解成多个小块，把这些小块分批发给浏览器，浏览器收到后再组装复原。

- 这样浏览器和服务器都不用在内存里保存文件的全部，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。

- **这种“化整为零”的思路在 HTTP 协议里就是“chunked”分块传输编码，在响应报文里用头字段<u>“Transfer-Encoding: chunked”</u>来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。**

  - 注意：Transfer-Encoding字段最常见的值是chunked，但也可以用gzip、deflate等，表示传输时使用了压缩编码。注意这与Content-Encoding不同，**Transfer-Encoding在传输后会被自动解码还原出原始数据，而Content-Encoding则必须由应用自行解码**

- **<u>“Transfer-Encoding: chunked”和“Content-Length”</u>这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现**，一个响应报文的传输要么是长度已知，要么是长度未知（chunked），这一点你一定要记住。

- **分块传输在末尾还允许有"拖尾数据"，由<u>响应头字段Trailer</u>指定**

- **分块传输的编码规则：**

  - 每个分块包含两个部分，长度头和数据块
  - 长度头是以CRLF（回车换行，即\r\n）结尾的一行明文，用16进制数字表示长度
  - 数据库紧跟在长度头后，最后也用CRLF结尾，但数据不包含CRLF
  - 最后用一个长度为0的块表示结束，即"0\r\n\r\n"
  - ![image-20221020220023482](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221020220023482.png)

  





#### 2.3 **范围请求**

- 有一个问题：
  - 比如你在看电视剧，但是你想跳过片头，直接看正片。这实际上是想获取一个大文件中的片段数据，而分块传输没有这个能力
  - HTTP 协议为了满足这样的需求，提出了**“范围请求”（range requests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零”。**
- 范围请求不是 Web 服务器必备的功能，可以实现也可以不实现，所以**服务器必须在响应头里使用字段“Accept-Ranges: bytes”明确告知客户端：“我是支持范围请求的”。**
- **如果不支持的话该怎么办呢？服务器可以发送“Accept-Ranges: none”，或者干脆不发送“Accept-Ranges”字段，这样客户端就认为服务器没有实现范围请求功能**，只能老老实实地收发整块文件了。
- **请求头Range是HTTP范围请求的专用字段**
  - 格式是"**bytes=x-y**"，其中的x和y是以字节为单位的数据范围
  - 注意：**x、y表示的是"偏移量"，范围必须从0计数**
  - 例如：前10个字节表示为"0-9"，第二个10字节表示为"10-19"，而"0-10"实际上是前11个字节
- **Range的格式**
  - 起点x和终点y可以省略，能够很方便地表示正数或者倒数的范围。
  - 假设文件是100个字节，那么：
    - "0-"表示从文档起点到文档终点，相当于"0-99"，相当于整个文件
    - "10-"是从第10个字节开始到文档末尾，相当于"10-99"
    - ”-1“是文档的最后一个字节，相当于"99-99"
    - "-10"是文档末尾倒数10个字节，相当于"90-99"
- 服务器收到Range字段后，需要做四件事：
  1. **它必须检查范围是否合法**。比如文件只有100个字节，但请求"200-300"，这就是范围越界了。服务器就会返回状态码**416**，意思是"你的范围请求有误，我无法处理，请再检查一下"
  2. **如果范围正确，服务器就可以根据Range头计算偏移量，读取文件的片段了**。返回状态码"**206 Partial Content**"，和200的意思差不多，但表示body只是原数据的一部分
  3. **服务器要添加一个响应头<u>Content-Range</u>，告诉片段的实际偏移量和资源的总大小，格式是"<u>bytes x-y/length</u>"，与Range头区别在没有"="，范围后多了总长度**。
     - 例如：对于"0-10"的范围请求，值就是"bytes 0-10/100"
  4. 最后就是发送数据了，直接把片段用TCP发给客户端，一个范围请求就算是处理完了
- **不仅看视频的拖拽进度需要范围请求，常用的下载工具里的多段下载、断点续传也是基于它实现的**，要点是：
  - 先发个HEAD请求，看服务器是否支持范围请求，同时获取文件的大小
  - 开N个线程，每个线程使用Range字段划分出各自负责下载的片段，发请求传输数据
  - 下载意外中断也不怕，不必从头再来一遍，只需要根据上次的下载记录，用Range请求剩下的那一部分就可以了







#### 2.4 多段数据

- 上面说的范围请求一次只获取一个片段，**其实它还支持在Range头里使用多个"x-y"，一次性获取多个片段数据**
- 这种情况需要使用一种特殊的MIME类型：”**multipart/byteranges**“，**表示报文的body是由多段字节序列组成的，并且还要用一个参数"boundary=xxx"给出段之间的分隔标记**
- ![image-20221020222311072](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221020222311072.png)
  - 每一个分段必须以"--boundary”开始（前面加两个"-"）
  - 之后要用"Content-Type"和"Content-Range"标记这段数据的类型和所在范围
  - 然后就像普通的响应头一样以回车换行结束
  - 在加上分段数据，最后用一个"--boundary--"（前后各有两个"-"）表示所有的分段结束









### 3.HTTP的连接管理

#### 3.1 长连接与短连接

- 所谓**短连接是指HTTP每次收发消息都会创建和关闭TCP连接**, 对于有大量HTTP请求的场景，收发效率低下。
- 针对短连接暴露出的缺点，HTTP协议就提出了"长连接"的通信方式，也叫"持久连接"、"连接保活"、"连接复用"
  - **即每次建立长连接后，后继的HTTP请求会复用第一个HTTP请求时建立的TCP连接，而无需关闭，再创建新的TCP连接**
- ![image-20221021164902638](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021164902638.png)





#### 3.2 连接相关的头字段

- 因为长连接对性能的改善效果显著，所以**在HTTP/1.1中的连接都会默认启用长连接**

- 客户端/服务器都可以用**`Connection: keep-alive`**显示声明启用长连接。

- **注：** 长连接如果长期闲置，会造成资源浪费，所以需要有长连接的关闭控制。

- **控制长连接关闭的3种方式。**

  - Connection头字段声明连接终止， 如果是最后一个请求，客户端可以在请求中带`Connection:close`，服务器端在返回响应报文后，回应`Connection:close`，并调用API终止连接

  - 公共头字段：`Keep-Alive: timeout=value1，max=value2`

    - **表示本次TCP连接持续多长时间或响应多少个请求后关闭，前置条件是Connection必须设置为keep-alive.**
    - WEB服务器对长连接的控制[Nginx]：keepalive_timeout、 keepalive_requests，含义和Keep-Alive一致。

  - 注: Connection和Keep-Alive在HTTP/2里已经被禁用。

    





#### 3.3 队头阻塞

- 基于HTTP的收发工作模式，多个请求放在一个FIFO的队列中，队列中的一个请求，必须收到响应消息后才能发起下一个请求，**如果队头请求意外阻塞，则导致整个队列阻塞**。
- **HTTP1.1中的解决方法是并发连接**，针对一个域名，浏览器允许开6-8个连接。这样，把请求分散到多个队列中，某种意义上缓解了队头阻塞问题。如果连接数量仍然太少，还可以用**域名分片Domain Sharding**，即多个域名映射到一个IP,即可以并发6*域名的连接，进一步缓解了队头阻塞的负面影响。
- **补充：**
  - 长连接是hop-by-hop的逐跳属性，而不是链路属性，是否使用长连接，是相邻设备协商的结果。
  - Connection的其它用途：
    - Connection: xxx,yyy 
      - **xxx,yyy代表不希望由代理服务器继续向前传递的头字段。**
    - 头字段分为逐跳传输头字段，和全链路传输字段，如keep-alive是逐跳传输头字段。xxx,yyy表达的是非逐跳传输头字段，通过Connection: xxx,yyy 让它们达到类似逐跳传输头字段的效果。
    - 标准的逐跳传输（hop-by-hop）头（Keep-Alive, Transfer-Encoding, TE, Connection, Trailer, Upgrade (en-US), Proxy-Authorization and Proxy-Authenticate）
  - 在有陈旧代理服务器参与的场景，Connection字段使用的注意事项：
    - client — proxy server — web server
    - 如果proxy server能识别Connection头字段但不支持keep-alive，则和proxy-server的连接退化为短连接，各段连接以协商结果为准。
    - 如果proxy server不能识别Connection头字段，它会复制client和web server的Connection头字段，而和proxy-server的连接退化为短连接，结果会使得client，web server误以为对端支持长连接，并复用该连接，而实际连接断开。可以引入proxy-connection，老旧proxy server 将复制该头字段，而新的proxy server将在下一跳中用connection头字段代替。
  - **因为TCP协议还有"慢启动""拥塞窗口"等特性，通常新建立的<u>"冷连接"会比打开了一段时间的"热连接"要慢一些</u>，所以长连接比短连接还多了这一层的优势**
  - **在长连接中的一个重要问题是如何正确地区分多个报文的开始和结束，所以最好总是用"Content-Length"头明确响应实体的长度，正确标记报文结束**。如果是流式传输，body长度不能立即确定，就必须用分块传输编码
  - **利用HTTP的长连接特性对服务器发起大量请求，导致服务器最终耗尽资源"拒绝服务"，这就是常说的DDoS**
  - Connection字段还有一个取值：
    - `Connection：Upgrade`，配合状态码101表示协议升级，例如从HTTP切换到WebSocket

- **问题：**
  - **在开发基于 HTTP 协议的客户端时应该如何选择使用的连接模式呢？短连接还是长连接？**
    - 根据应用场景决定选择短连接或长连接，如果只是一次性的请求，用短连接。 如果是大量请求，可以用长连接。
  - **应当如何降低长连接对服务器的负面影响呢？**
    - 客户端可以在发送最后一次请求时带Connection: close头字段，显示关闭连接，服务器端可以设置keepalive_timeout, keepalive_requests参数，条件则触发关闭连接。









### 4. HTTP的重定向和跳转

- 点击超链接之后会发生什么？

  - 浏览器首先要解析连接中的URI，再用这个URI发起一个新的HTTP请求，获取响应报文后就会切换显示内容，渲染出新URI指向的页面
  - **这样的跳转动作是由浏览器的使用者主动发起的，可以称为"主动跳转"**。但还有一类跳转是由服务器来发起的，浏览器使用者无法控制，相对的就可以称为"**被动跳转**"，或者叫做"**重定向**"

- 重定向的过程

  - 用Chrome访问URI“/18-1"，它会使用302立即跳转到"/index.html"

    - ![image-20221021173730334](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021173730334.png)
    - 这一次"重定向"实际上发送了两次HTTP请求，第一个请求返回了302，然后第二个请求就被重定向到了"/index.html"。
    - 这样的重定向是**用户无感知的**

  - 看第一个请求返回的响应报文：

    - ![image-20221021173900348](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021173900348.png)

    - 出现了一个新的头字段"Location：/index.html"，这就是301/302重定向的秘密所在

    - **<u>"Location"字段属于响应字段</u>，必须出现在响应报文里。但只有配合301/302状态码才有意义，它标记了服务器要求重定向的URI**，这里就是要求浏览器跳转到"index.html"

    - 浏览器收到301/302报文，会检查响应头里有没有"Location。如果有，就从字段值里提取出URI，发出新的HTTP请求，相当于自动替我们点击了这个链接

    - 注意：**在重定向时如果只是在站内跳转，可以使用相对URI。但如果要跳转到站外，就必须用绝对URI**

      - 绝对URI：就是完整形式的URI，包括scheme、host：port、path等
      - 相对URI：就是省略了scheme和host：port，只有path和query部分，是不完整的

      

- 重定向状态码

  - 301 Moved Permanently 永久重定向，即原URI永久失效，浏览器，爬虫可据此更新到新URI。
  - 302 Found 临时重定向，即原URI临时生效，未来会恢复，浏览器，爬虫不会更新。
  - 303 See Other，通常作为 PUT 或 POST 操作的返回结果，它表示重定向链接指向的不是新上传的资源，而是另外一个页面，比如消息确认页面或上传进度页面。而**请求重定向页面的方法要总是使用 GET。**
  - 307 Temporary Redirect，临时重定向，类似302，但要求新发出的请求头和请求体保持不变。
  - 308 Permanent Redirect 永久重定向，类似301，但要求新发出的请求头和请求体保持不变。

- 重定向相关头字段

  - **Location:URI 服务端响应头字段，浏览器据此发起新的URI请求，URI即可以是相对路径，也可以是绝对路径的。**

  - **Referer: 请求头字段，表示发起重定向的源URI。**

  - `Refresh:5;URL=XXX` 服务端响应头字段，延时重定向。

    - 上面这个表示告诉浏览器5秒钟后再跳转

  - 关于Referer的补充：

    - 在以下两种情况下，Referer 不会被发送：
      - 来源页面采用的协议为表示本地文件的 “file” 或者 “data” URI；
      - 当前请求页面采用的是非安全协议，而来源页面采用的是安全协议（HTTPS）
    - Referer的用途：统计分析、日志记录以及缓存优化。
    - Referrer-Policy的设置决定了Referer字段携带的URI格式，URI的组成包括origin, path, query string
      策略可以是
      - Referrer-Policy: no-referrer 
        - 不传Referer
      - Referrer-Policy: no-referrer-when-downgrade
        - 安全等级降级不传，不考虑是否同源
      - Referrer-Policy: origin
        - 仅传origin，不考虑是否安全等级下降
      - Referrer-Policy: origin-when-cross-origin
        - 同时考虑安等和同源，跨站或安全等级下降时仅传origin
      - Referrer-Policy: same-origin 
        - 仅同源传Referer，非同源不传
      - Referrer-Policy: strict-origin 
        - 安全等级降级下降不传，其它情况只传origin，不包括path, query str
      - Referrer-Policy: strict-origin-when-cross-origin 
        - 缺省设置，同时考虑同源和安全，同源传完整URI, 跨域且安全不降低，传Origin，否则不传
      - Referrer-Policy: unsafe-url 
        - 任意情况都传

    - 注：
      - 就是考虑2个维度，是否同源，安全等级是否下降。
      - origin就是仅传URI的origin部分，不包括path，query string

- 重定向的应用场景
  - 使用重定向跳转，核心是要理解**重定向**和**永久/临时**这两个关键词
  - 什么时候需要重定向
    - 一个最常见的原因就是**资源不可用**，需要用另一个新的URI来代替
      - 不可用的原因：域名变更、服务器变更、网站改版、系统维护等
    - 另一个原因就是**避免重复**，让多个网址都跳转到一个URI，增加访问入口的同时还不会增加额外的工作量
      - 例如，有的网站都会申请多个名称类似的域名，然后把它们再重定向到主站上
  - 选择301还是302
    - 301的含义是"**永久**"的
      - 如果域名、服务器、网站架构发生大幅度的改变，就要用301"永久重定向
    - 302的含义是"**临时**"的
      - 原来的URI在将来的某个时间点还会恢复正常。
- 重定向的相关问题
  - 第一个问题是**性能损耗**
    - 重定向的机制决定了一个跳转会有两次请求应答，比正常的访问多了一次
    - 所以重定向应当适度使用，绝不能滥用
  - 第二个问题是**循环跳转**
    - 如果重定向的策略设置欠缺考虑，可能会出现"A=>B=>C=>A"的无线循环
    - 所以HTTP协议特别规定，浏览器必须具有检测”循环跳转“的能力，在发现这种情况时应当停止发送请求并给出错误提示
  - **301 和 302 的异同点**
    - 301和302跳转的的语义不同，区别核心在于临时和永久。
    - 301永久跳转，浏览器或搜索引擎除了执行跳转，还要执行额外动作，如更新书签，SEO等，适用场景包括，域名更新，导流，网站重构等。
    - 302临时跳转，浏览器或搜索引擎仅执行跳转，无后继动作。适用场景包括，web服务器维护等。







### 5.HTTP的Cookie机制

#### 5.1 什么是Cookie

- HTTP协议是无状态的，即上一次请求和本次请求没有任何关系，对于某些事务性需求，如购物，需要记录访问者身份，如果不能记录用户身份信息，每次请求需要验证身份，显然十分不便。
- 因此，引入了cookie,由服务端对用户信息做标记，客户端后继请求带上该信息，即解决了身份识别的问题。
- cookie【RFC6265】是服务器委托浏览器存储在浏览器本地的kv对形式的用户身份标识信息。
- 工作流程：
  - 客户端访问页面，执行登录动作
  - 服务端识别用户身份，并在响应报文中用Set-Cookie: key=value + 若干参数设置cookie标识用户身份
  - 客户端后继请求消息中带上相关cookie，标识客户端
  - 服务端通过cookie识别用户身份，并进行后继动作。
  - **注: cookie不是HTTP标准，它使用的参数之间的分隔符是";“而不是”,"**
  - ![image-20221021194147469](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021194147469.png)





#### 5.2 Cookie的属性

- ![image-20221021200126075](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021200126075.png)

- Cookie的生命周期

  - 也就是它的有效期，让它只能在一段时间内可用。一旦超过这个期限浏览器就认为是Cookie失效，在存储里删除，也不会发送给服务器
  - Cookie的有效期可用用Expires和Max-Age两个属性来设置
    - **”Expires"**俗称"过期时间"，用的是绝对时间点，可用理解为"截止日期"
    - "**Max-Age**"用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上Max-Age，就可以得到失效的绝对是就
    - 两者可以同时出现，但**浏览器会优先采用Max-Age计算失效期**

- Cookie的作用域

  - “**Domain**”和“**Path**”指定了**Cookie所属的域名和路径**，浏览器在发送Cookie前会从URI中提取出host和path部分，对比Cookie的属性。如果不满足条件，就不会在请求头里发送Cookie
  - 使用这两个属性可以为不同的域名和路径分别设置各自的Cookie
    - 如"/19-1"用一个Cookie，"/19-2"用另外一个Cookie，两者互不干扰。
    - 不过通常Path就用一个"/"或直接省略，表示域名下的任意路径都允许使用Cookie

- Cookie的安全性

  - **HttpOnly**
    - 此属性会告诉浏览器，**此Cookie只能通过浏览器HTTP协议传输**，禁止其他方式访问，浏览器的JS引擎就会禁用document.cookie等一切相关的API
  - **SameSite**
    - 此属性可以防范"跨站请求伪造"(XSRF)攻击
    - 设置成**"SameSite=Strict"可以严格限定Cookie不能随着跳转链接跨站发送**
    - 而**"SameSiteLax"则略宽松一点，允许GET/HEAD等安全方法，但禁止POST跨站发送**
  - **Secure**
    - 此属性表示这个Cookie仅能用HTTPS协议加密传输，明文的HTTP协议会禁止发送

- Cookie的应用

  - 身份识别
    - 保存用户的登录信息，实现会话事务
  - 广告跟踪

- 问题

  - **如果 Cookie 的 Max-Age 属性设置为 0，会有什么效果呢？**

    - cookie立即失效。

  - **Cookie 的好处已经很清楚了，你觉得它有什么缺点呢？**

    - 如果没有合理设置有效期，有效范围，安全性，如HttpOnly, SameSite等，则有潜在安全风险。

    







### 6.HTTP的缓存控制

#### 6.1 什么是缓存控制

- HTTP缓存是HTTP/1.1中加快访问速度，提高性能的主要手段。基于HTTP的工作模型，**缓存既可以保存在客户端，也可以保存在代理服务器端**
- **缓存保存的是请求资源的副本**，请求的资源可能会动态更新，一段时间前取得的资源，现在可能已经变更，如何在效率和可用性间达成平衡是一个问题
- **HTTP采取的策略是根据更新频率区分资源，对于频繁更新，动态生成的数据，不缓存**。
- 另外，为可缓存资源做有效期标记，根据资源更新的频率，设定不同长度的缓存有效期【s-maxage, max-age,Expires】。为了更好的使用缓存，HTTP还设计了缓存有效性验证机制，即当缓存过期后，可以去服务器验证被缓存的资源是否可用，这通过添加头字段标记资源的属性，如最后修改时间，Etag等来实现。
- 缓存功能使用的头字段为Cache-control,服务器端和客户端都可以使用，由对端响应处理。





#### 6.2 服务器的缓存控制

- 流程：
  - 浏览器发现缓存无数据，于是发送请求，向服务器获取资源
  - 服务器响应请求，返回资源，同时标记资源的有效期
  - 浏览器缓存资源，等待下次重用
  - ![image-20221021201636054](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021201636054.png)
- **服务器端指示客户端的缓存参数或行为：**
  - **`Cache-control: max-age=t`， 指定响应消息关联的资源的有效期为t秒,**
    - 计算时间从date开始记为t，假定传输时间为t1,则本地实际缓存时间为t-t1。
    - 注：上面是粗略的计算方法，下面有精确的关于判断缓存有效期的计算。
    - 注： cache-control和cookie中的max-age计算时间的方式是不同的。**cookie时间起点是接收时间，cache时间起点是消息产生时间，中间相差一个传输时间。**
  - `Cache-control: no-store`，不保存缓存。
  - `Cache-control: no-cache，max-age=t` **先回源验真，再决定是否使用缓存**。注：不考虑max-age是否超时。因为已经回源验证了资源的有效性，无效则从服务器取，否则用缓存。再考虑max-age没有意义。**（可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本）**
  - `Cache-control: must-revalidate，max-age=t`**缓存超时验真，否则可直接用**。**（缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证）**
  - ![image-20221021203046758](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021203046758.png)







#### 6.3 客户端的缓存控制

- 不止服务器可以发"Cache-Control"头，浏览器也可以发"Cache-Control"，也就是说请求-应答双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略
- **客户端指示服务器端行为**：
  - 刷新，请求消息中将添加以下头字段， `Cache-Control: max-age=0`
  - 强制刷新，请求消息中将添加以下头字段， `Cache-Control: no-cache`
  - `max-age,max-stale,min-fresh`,是告诉服务器/代理服务器如何使用自己缓存的资源，而不是如何用自己的缓存，理解这个很重要。
    - 另外很重要的一个参数值是age
    - `max-age`是告诉代理服务器，你提供的缓存资源的age不能超过我发给你的max-age,否则需要回源服务器取。
    - `max-stale`是告诉代理服务器，你提供的缓存资源的max-age减age之差不能大于max-stale指定的时间，否则需要回源服务器取，或不设置时间，表示无论过期多久都可以接收。
    - `min-fresh`是告诉代理服务器，你提供的缓存资源的max-age减age之差不能小于min-fresh指定的时间，否则需要回源服务器取。





#### 6.4 条件请求

- HTTP协议定义了一系列"**If**"开头的"**条件请求**"字段，专门用来检查验证资源是否过期
- 条件请求一共有5个头字段，最常用的是**`if-Modified-Since和If-None-Match`**这两个。需要第一次的响应报文预先提供**`Last-modified和ETag`**，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的
  - `if-Modified-Since`表示询问从最后修改时间到现在有没有改变过
  - `If-None-Match`表示询问有没有资源符合If-None-Match后面携带的条件的
  - `Last-modified`表示文件的最后修改时间
  - `ETag`是"实体标签"（Entity Tag）的缩写，**是资源的一个唯一标识，主要用来解决修改时间无法准确区分文件变化的问题**
    - 比如一个文件在一秒内修改了多次，但因为修改时间是秒级，所以这一秒内的新版本无法区分
    - 再比如一个文件定期更新，但有时会是同样的内容，实际上没有变化，用修改时间就会误以为发生了变化，传送给浏览器就会浪费带宽
    - **使用ETag就可以精确地识别资源的变动情况，让浏览器能够更有效地利用缓存**
    - **ETag还有强弱之分**
      - 强ETage要求资源在字节级别必须完全相符
      - 弱ETag在值前面有个"W/"标记，只要求资源在语义上没有变化，但内部可能会有部分发生了改变（例如HTML里的标签顺序调整，或者多了几个空格）
- 如果资源没有变，服务器就回应一个"**304 Not Modified**"，**表示缓存依然有效**，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了
- ![image-20221021205942965](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221021205942965.png)





#### 6.5 小结

- 小结：

  - 对于**response中没有设置Cache-Control的资源**，Chrome不会缓存，意味着**刷新将重取资源。**

  - 对于**设置了Cache-Control的资源**，如Cache-Control:max-age=t,则**分2种情况**，**直接访问页面和内嵌资源**。

    - 直接访问页面，刷新时会携带Cache-Control:max-age=0,意味着取服务器最新资源
    - 内嵌资源则直接使用缓存。
    - 如果直接访问页面还携带了Last-Modified 和或ETag,则Chrome后继访问会携带If-modified-since,If-None-match,走条件请求流程，返回304。
      特例：响应中有Last-Modifed但没有Cache-Control或Expires,采用启发式算法Heuristic计算缓存时间，通常是(DownloadTime-Last-modified)*10%

  - **判断缓存是否过期就是简单用下面的表达式**

    - `response_is_fresh = (freshness_lifetime > current_age)`
    - 基本的逻辑不是freshness_lifetime在浏览器内部倒计时，而是**current_age在累积，然后比较大小**。
    - 所以**fressness_lifetime是一个固定的静态值**， 可以有4个来源，**优先级从高到低分别是s-maxage,max-age,Expires,Expires2[启发式算法系统预估时间]。**
    - 注1：s-maxage仅对共享缓存有效，私有缓存将忽略
    - 注2：Expires是一个头字段，而s-maxage,max-age是Cache-Control的可选项，所以不能在MDN搜HTTP头字段获得
    - 系统预估时间，是因为某些资源未提供上述3个时间值，而又有必要缓存。
    - 预估时间计算公式[RFC7234]：(DownloadTime-LastModified)*10%
    - Chrome,Webkit遵循上述规范
    - Firefox,在上述值和OneWeek中取小的那个值

  - **current-age的计算**

    - 根据公式`current-age= corrected_initial_age+resident_time`
    - **基本逻辑是本地驻留时间+网络传输消耗的时间**。
    - `resident_time = now - response_time`（本地驻留时间=现在的时间-返回时的时间）
    - `corrected_initial_age = max(apparent_age,corrected_age_value);`（网络传输消耗时间）
      - `apparent_age = max(0,response_time-date_value)`
        - **apparent_age相当于是回应在网络传输消耗的时间。**
      - current-age在**corrected_age_value这个分支和age有关联。**
        - `corrected_age_value = age_value + response_delay`
          - response_delay = response_time -request_time
          - **response_delay相当于消息请求响应双向传输花费的时间。**
      - 注：corrected_initial_age应对2种场景：
        - 直接从服务器获取消息，对应apparent_age，不考虑age
        - 从代理服务器获取消息，对应corrected_age_value，需考虑age

    

- 问题

  - **客户端Cache-Control: max-age=0和Cache-Control: no-cache是否相同？**
    - 有区别：**浏览器刷新会带Cache-Control: max-age=0,强制刷新会带Cache-Control: no-cache**
    - max-age = 0 意味着代理服务器必然回源服务器并拉取完整资源，因为代理服务器上的age大概率>0。
    - no-cache意味着代理服务器要先去源服务器验证缓存是否过期，是则拉取完整资源，过程不同，但效果等同于max-age=0,否则代理服务器可以给客户端缓存，这就和max-age=0完全不同。
  - **Cache 和 Cookie 都是服务器发给客户端并存储的数据，你能比较一下两者的异同吗？**
    - 不同点：
      - 目的不同，存储内容不同，行为不同。
      - Cache是为了加快访问速度，存储的是请求数据本身。
      - Cookie是为了HTTP记录会话状态，存储的是用户标记信息。
      - Cookie会随请求头发送到服务器端。
      - Cache不会发送到服务器端。
    - 相同点：
      - 都是服务器存储在客户端上的数据。
      - 都可以用max-age控制生存期。
  - **即使有“Last-modified”和“ETag”，强制刷新（Ctrl+F5）也能够从服务器获取最新数据（返回 200 而不是 304），请你在实验环境里试一下，观察请求头和响应头，解释原因。**
    - 强制刷新将忽略收到的Last-modified,Etag消息，请求中带上Cache-control: no cache头，不带If-None-Match,If-Modifed-Since头，**即提供某种机制能无视cache，强制从服务器上获得最新的数据。**









### 7.HTTP的代理服务

- **通信数据转发程序：代理、网关、隧道**

  - **代理**

    - **代理是一种有转发功能的应用程序，它扮演了位于服务器和客户端"中间人"的角色**

    - 接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端

  - **网关**

    - **网关是转发其他服务器通信数据的服务器**

    - 接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理

  - **隧道**

    - **隧道是在相隔甚远的客户端和服务器之间进行中转，并保持双方通信连接的程序**


    

- 典型的HTTP的收发模型，只有客户端和服务端2个角色参与。

  - 但真实的HTTP应用场景，往往会在二者之间的传输链路上引入1个或多个代理服务器。
  - 代理服务器在HTTP通讯模型中扮演着双重的角色：从客户端看来，它是服务器；从服务器看来它是客户端。
  - 代理服务器可以1个或多个，形成有序的数据传输链条，对任意2个临近的节点，它们仍然遵循HTTP一发一收的工作模式。代理服务器不产生数据，但会对数据进行加工，分发，缓存。
  - client — proxy server1 — proxy server2 — … proxy servern — origin server

- 代理服务器的作用

  - 负载均衡，接收用户端请求，并把请求按一定算法，分发到后端的真实服务器
  - 健康检查，用‘心跳’等机制从集群中剔除不可靠的服务器
  - 安全防护，使用安全策略，如限IP限流，抵御外网攻击。
  - 数据过滤，报文检查，修改，施加管理策略。
  - 加密卸载，外网使用TLS加密通讯，认证，安全的内网不加密，消除加解密成本
  - 内容缓存，缓存复用服务器响应

- 代理相关头字段

  - 可以用`通用字段Via`标记HTTP传输路径中间经过的代理服务器

    - 每当报文经过一个代理服务器，代理服务器就会把自身信息追加到字段的末尾
    - ![image-20221022152246704](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221022152246704.png)

  - 代理服务器代理发送请求，所以源客户端信息丢失，可以用`X-Forwarded-For`和`X-Real-IP`标记

    - `X-Forwarded-For`,**从源客户端开始，每经过一个代理服务器添加一个IP**[非标准，但是事实标准头字段de-facto standard header]
      - **在字段的最左边的IP就是客户端的地址**
    - `X-Real-IP`,**仅包含源客户端IP**

  - 抓包处理：

    - ![image-20221022152823167](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221022152823167.png)

    - 客户端55061先用三次握手连接到代理的80端口，然后发送GET请求

    - 代理不直接生产内容，所以就代表客户端，用55063端口连接到源服务器，也是三次握手

    - 代理成功连接源服务器后，发出了一个HTTP/1.0的GET请求

    - 因为HTTP/1.0默认是短连接，所以源服务器发送响应报文后立即用四次挥手关闭连接

    - 代理拿到响应报文后再发回给客户端，完成了一次代理服务

      

- 代理协议

  - 上述方法的缺点是，需要修改HTTP头字段，执行效率低，另外在HTTPS的情况下不可行，所以又引**入HAProxy代理协议，通过在HTTP头部再封装一层头，来实现代理转发**，格式如下：

    - ```js
      PROXY TCP4 1.1.1.1 2.2.2.2 55555 80
      HTTP头部…
      HTTP 实体…
      ```

      - **开头必须是`PROXY`五个大写字母，然后是"TCP4"或者"TCP6"，表示客户端的IP地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行(\r\n)结束**

  - 此方案不修改HTTP头字段，执行效率高，方案实现了类似带X-Real-IP头字段的效果,缺点是没有携带每跳代理服务器的信息，即Via和/或X-Forwarded-For的功能。

    

- 问题

  - **你觉得代理有什么缺点？实际应用时如何避免？**
    - 增加了复杂度，无法避免
    - 增加了时延，无法避免
    - 增加了安全性风险，采用HTTPS
  - **你知道多少反向代理中使用的负载均衡算法？它们有什么优缺点？**
    - 轮询，一致性hash，随机，链路最短，最近最少使用

- 补充

  - "Via"是HTTP协议里规定的标准头字段，但有的服务器返回的响应报文里会使用"X-Via"，含义是相同的
  - 因为HTTP是明文传输，请求头很容易被篡改，所以"X-Forwarded-For"也不是完全可信的









### 8.HTTP的缓存代理

- HTTP的缓存代理就是提供缓存服务的代理服务器，由于它处于HTTP传输路径的中间位置，所以它兼具Cache-control在服务器，客户端2个方向的设置，同时又特有代理服务器的若干缓存配置属性。

- 缓存代理服务

  - 在没有缓存的时候，代理服务器每次都是直接转发客户端和服务器的报文，中间不会存储任何数据，只有最简单的中转功能
  - 加了缓存之后
    - 代理服务器收到源服务器发来的响应数据后需要做两件事。第一个当然是把报文转发给客户端，而第二个就是把报文存入自己的Cache里
    - 下一次再有相同的请求，代理服务器就可以直接发送304或缓存数据，不必再从源服务器那里获取。这就降低了客户端的等待时间，同时节约了源服务器的网络带宽
  - 缓存代理需要有一些新的"Cache-Control"属性来对它做特别的约束

- 源服务器的缓存控制

  - 之前介绍了4种服务端的"Cache-Control"属性：max-age、no_store、no_cache和must-revalidate。这4种缓存可以约束客户端，也可以约束代理

    - 但是客户端和代理不一样。客户端的缓存只是用户自己使用，而代理的缓存可能会为非常多的客户端提供。所以需要对它的缓存再多一些限制条件

  - **要区分客户端上的缓存和代理上的缓存，可以使用两个新属性"private"和"public"**

    - **"private"**表示缓存只能在客户端保存，是用户"私有"的，不能放在代理上与别人共享。
    - 而"**public**"的意思就是缓存完全开放，谁都可以存，谁都可以用

  - 其次，缓存失效后的重新验证也要区分开（即使用条件请求"Last-modified"和"ETag"）

    - **`"must-revalidate"`是只要过期就必须回源服务器验证**
    - **而新的`"proxy-revalidate"`只要求代理的缓存过期后必须验证，客户端不必回源，只验证到代理这个环节就行了**

  - 再次，**缓存的生存时间可以使用新的`"s-maxage"`（s是share的意思，注意maxage中间没有"-"），只限定在代理上能够存多久，而客户端仍然使用"max_age"**

  - 还有一个代理专用的属性**`"no-transform"`**.

    - **代理有时候会对缓存下来的数据做一些优化，比如把图片生成png、webp等几种格式，方便今后的请求处理，而"no-transform"就会禁止这样做，不许"偷偷摸摸搞小动作"**

  - 完整的服务器端缓存控制策略，可以同时控制客户端和代理

    - ![image-20221022162829374](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221022162829374.png)

    

- 客户端的缓存控制

  - **`only-if-cached`,只接受缓存，不接受源服务器的响应。如果代理上没有缓存或者缓存过期，就返回504**

  - **`max-age`,表示只接受age<max-age的缓存**

  - **`max-stale`,可接受的过期时间**

    - 如果代理上的缓存过期了也可以接受，但不能过期太多，超过x秒就不要

  - **`min-fresh`,至少剩余的保鲜时间**

    - 缓存必须有效，而且必须在x秒后依然有效

  - ![image-20221022163717977](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221022163717977.png)

    

- 其他问题

  - 第一个是"**Vary**"字段
    - 它是内容协商的结果，相当于报文的一个版本标记
    - 同一个请求，经过内容协商后可能会有不同的字符集、编码、浏览器等版本，缓存代理必须要储存这些不同的版本
    - 当在收到相同的请求时，代理就读取缓存中的"Vary"，对比请求头里相应的字段，如果和上一个请求的完全匹配，就表示版本一致，可以返回缓存的数据
  - 另一个问题是"**Purge**"，也就是"缓存清理"，它对于代理也是非常重要的功能，例如：
    - 过期的数据应该及时淘汰，避免占用空间
    - 源站的资源有更新，需要删除旧版本，主动换成最新版（即刷新）
    - 有时候会缓存了一些本不该存储的东西，必须尽快把他们删除
    - 清理缓存的方法有很多，比较常用的是使用自定义请求方法"PURGE"，发给代理服务器，要求删除URI对应的缓存数据
  - **加入了代理后 HTTP 的缓存复杂了很多，试着用自己的语言把这些知识再整理一下，画出有缓存代理时浏览器的工作流程图，加深理解。**
    - 客户端发起请求时先检查是否有本地缓存，缓存是否过期，根据缓存策略，决定是否发送报文
    - proxy-revalidate, max-age>0, 不发消息，直接用本地缓存
    - proxy-revalidate, max-age <=0, 发消息，如果s-maxage>0,用代理缓存，否则由代理向源服务器发起请求
    - no-store,不用缓存
    - no-cache,源服务器验真
    - must-revalidate, 过期源服务器验真
  - **缓存的时间策略很重要，太大太小都不好，你觉得应该如何设置呢？**
    - 频繁变动的资源max-age时间设短一点，反之长一点













## 四.安全篇

### 1.HTTPS是什么？SSL/TLS又是什么？

- 为什么要有HTTPS?

  - 因为HTTP消息是明文传输的，任何中间人都可以截获，查看，修改HTTP消息，所以HTTP是不安全。

- 什么是安全？

  - 网络通讯安全，要解决4方面的问题：

    - **机密性**： **用加密算法加密来保证消息的机密性，即消息只对通讯双方可见，中间人即使截获，也无法看到消息内容。**
      - 对称加密速度快，但秘钥交换是个问题，而且最好秘钥不固定，每个会话一个秘钥。
      - 通常用非对称算法加密对称秘钥。而秘钥产生，交换过程是重点和难点。
    - **完整性**： **消息不允许被篡改，如果没有完整性机制，中间人截获密文后，由于加密算法是已知的，可以伪造，变更消息发送**
      - 【存疑】：
        - 中间人不知道加密秘钥啊？
          - 和对称加密算法的分组方式有关，如GCM可以在加密的同时保证加密内容不被篡改。而采用ECB则用户无法感知接收的消息是否被篡改。
        - 不知这有什么用？
          - 攻击者拿不到秘钥，乱改的消息，解密出来的也是乱码，除了干扰接受者，不能有实质性的损害。目前使用的AES-256-GCM可以保证数据的加密强度，速度和不可篡改。仍然引入摘要算法保护数据的完整性。
        - 摘要算法在TLS中如何保证数据的完整性？
          - 注：对称加密的加密强度和算法，秘钥长度，分组方式有关。分组方式会影响密文是否有特征，能否被篡改，现代的分组方式如GCM带HMAC功能，能解决上述问题，防篡改底层实现也是用的摘要算法。另外摘要算法还可以用在数字签名中。所以消息完整性由摘要算法保证。
      - 完整性包括2个层面
        - 一个是对称加密算法如何保证数据的完整性，另外是非加密数据如何保证数据的完整性。
        - **无论何种数据，保证完整性的方式都是数字签名**。【摘要加加密】因为TLS1.2协商，需要2个rtt才能完成握手，所以证书的Certificate消息是非加密的，而TLS1.3，在收到Client的ClientHello后，server即进入加密状态，所以TLS1.3发送的Certificate消息也是加密的。
    - **身份验证**： 保证消息的发送者的身份是真实的，即核验网站/用户的身份。
    - **不可撤销**：保证由网站/用户发出的消息，不可抵赖。【TLS如何保证？】
    - 4者基本是递进关系

    

- 什么是HTTPS

  - HTTPS的RFC文档规定了**新的协议名"https"，默认端口号443**，至于其他的声明请求-应答模式、报文结构、请求方法、URI、头字段、连接管理等等完全沿用HTTP

  - 那既然没有新东西，HTTPS凭什么能做到机密性、完整性？

    - 要点就在于HTTPS名字里的S，它把HTTP下层的TCP/IP换成了SSL/TLS，由”**HTTP over TPC/IP**“变成了”**HTTP over SSL/TLS**“，让HTTP运行在了安全的SSL/TLS协议上，收发报文不再使用Socket API，而是调用专门的安全接口

  - ![image-20221022200632756](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221022200632756.png)

    

- SSL/TLS

  - SSL — Secure Sockets Layer
  - TLS — Transport Layer Security
  - TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术。
  - 浏览器和服务器在使用TLS建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为"密码套件"（cipher suite，也叫加密套件）
  - Cipher suite命名规则：
    - 基本形式：密钥交换算法 + 身份验证算法 + 对称加密算法+分组模式 + 摘要算法
    - 比如：`ECDHE-RSA-AES256-GCM-SHA384`，意思为：
      - 握手时使用 ECDHE 算法进行密钥交换，用 RSA 签名和身份认证，握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM，摘要算法 SHA384 用于消息认证和产生随机数。

- OpenSSL

  - OpenSSL是开源密码学程序库和工具包，是 SSL/TLS 的具体实现

- 问题：

  - **你能说出 HTTPS 与 HTTP 有哪些区别吗？**
    - 区别在于安全性，HTTPS即HTTP over TLS, HTTPS在TCP的基础上增加一个TLS安全层，基于TLS实现了HTTP通讯的安全性,包括4大方面：
      - 机密性，对称加密算法AES256加解密, 非对称算法实现秘钥交换ECDHE
      - 完整性, 摘要算法保证消息的完整性，SHA384
      - 身份确认, RSA证书确认通讯双方身份
      - 不可否认，RSA数字签名保证消息不可否
      - 另外，scheme为https, 端口号443，版本号仍然是HTTP/1.1
  - **你知道有哪些方法能够实现机密性、完整性等安全特性呢？**
    - 机密性：加密，通常用对称加密算法对HTTP消息进行加密，如AES256
    - 完整性：摘要算法保证完整性, 如SHA384。







### 2.对称加密和非对称加密

#### 2.1 什么是加密

- 加密（encrypt）就是把消息用某种方式转换成谁也看不懂的乱码，只有掌握特殊"钥匙"的人才能再转换出原始文本
- 这里的要素叫做"**密钥**”（key），加密前的消息叫做"**明文**"（plain text/clear text），加密后的乱码叫做"**密文**"（cipher text），使用密钥还原明文的过程叫"**解密**"（decrypt），是加密的反操作。加密解密的过程就是"**加密算法**"
- 按照密钥的使用方式，加密可以分为两大类：对称加密和非对称加密





#### 2.2 对称加密

- 对称加密 就是指 **加密和解密时使用的密钥都是同一个**，是"对称"的

  - 只要保证了密钥的安全，那整个通信过程就可以说具有了机密性
  - ![image-20221025205324978](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025205324978.png)
  - ![image-20221025201845388](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025201845388.png)

- 对称加密速度快，但无法解决**秘钥传递问题**，目前常见的有AES256,CHACHA20。

  - AES的意思是“高级加密标准”，密钥长度可以是127、192、256。是应用最广泛的对称加密算法
  - CHACHA20是Google设计的另一种加密算法，密钥长度固定为256位
  - **注:和一般意义上认知的密码不同，TLS中的“密钥”就是一长串的数字，不包括字符。**

  

- 加密分组模式

  - 加密分组可以**让算法用固定长度的密钥加密任意长度的明文，把小秘密（即密钥）转化为大秘密（即密文）**

  - 因为AES只能对固定长度的数据加密，因此需要配合分组算法，常用的分组模式有CCM,GCM和Poly1305。

  - 把上面的组合起来，就可以得到**TLS密码套件**中定义的对称加密算法，比如：

    - AES128-GCM，意思是密钥长度位128位的AES算法，使用的分组模式是GCM；
    - CHACHA20-Poly1305，意思是CHACHA20算法，使用的分组模式是Poly1305
    - 密码套件命名的基本形式：
      - 密钥交换算法+签名算法+对称加密算法+摘要算法
      - ![image-20221025205224443](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025205224443.png)

    



#### 2.3 非对称加密

- 对称加密有一个很大的问题：**如何把密钥安全地传递给对方，属于叫"密钥交换"**
  - 因为在对称加密算法中只要持有密钥就可以解密。
  - 如果你和网站约定的密钥在传递途中被黑客窃取，那他就可以在之后随意解密收发的数据，通信过程也就没有机密性可言了
  - ![image-20221025205348781](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025205348781.png)
- 所以就有了"非对称加密"（也叫**公钥加密算法**）
  - 他有两个密钥，一个叫"**公钥**"（public key），一个叫"**私钥**"（private key）。
  - 两个密钥是不同的，"不对称"，**公钥可以公开给任何人使用，而私钥必须严格保密**
  - 公钥和私钥有个特别的"**单向性**"，虽然都可以用来加密解密，但**公钥加密后只能用私钥解密；反过来，私钥加密后也只能用公钥解密**
  - ![image-20221025205403008](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025205403008.png)
  - ![image-20221025203656718](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025203656718.png)
- 非对称加密算法在TLS里有：DH、DSA、RSA、ECC等
  - RSA秘钥交换+加密解密
  - DH 秘钥交换
  - ECDHE 椭圆曲线密码交换
  - ECDSA 数字签名
  - 常用曲线：P-256[别名:prime256v1:secp256r1],x25519



##### 2.3.1 RSA握手解析

- ![image-20221025210103547](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025210103547.png)

  

- TLS握手过程

  - HTTP传输存在的安全问题：

    - 窃听：窃听报文的信息，获取通信内容
    - 篡改：篡改报文信息
    - 冒充：冒充身份

    所以HTTPS在HTTP和TCP之间加入了TLS协议来解决这个问题：

    - 信息加密：将HTTP交互信息加密
    - 校验机制：检查数据是否被第三方篡改过
    - 身份证书：证明身份

    而我们使用不同的密钥交换算法，TLS的握手过程可能会不太一样，在这里我们使用RSA密钥交换算法来解析一下TLS的握手过程

    

- RSA握手过程

  - ![image-20221025210208437](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025210208437.png)

  - TLS第一次握手

    - 客户端首先会发一个`Client Hello`消息，跟服务器打招呼

      这个消息里面包含着：

      - 客户端使用的 TLS 版本号
      - 支持的密码套件列表
      - 生成的**随机数**（Client Random），这个随机数会被服务器端保留，是生成对称加密的密钥的材料之一

  - TLS第二次握手

    - 当服务端收到客户端的`Client Hello`消息后，会返回一个`Server Hello`信息：

      - 确认的 TLS 版本号

      - 从密码套件列表中选择的一个密码套件

        > 此处选择的密码套件是有一个基本的格式的：
        >
        > **密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法**
        >
        > WITH 单词前面有两个单词，第一个单词是约定密钥交换的算法，第二个单词是约定证书的验证算法
        >
        > WITH 单词后面也有两个单词，第一个单词是对称算法，第二个单词是摘要算法
        >
        > 如：`Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256`的意思：
        >
        > - 由于 WITH 单词只有一个 RSA，则说明握手时密钥交换算法和签名算法都是使用 RSA；
        > - 握手后的通信使用 AES 对称算法，密钥长度 128 位，分组模式是 GCM；
        > - 摘要算法 SHA256 用于消息认证和产生随机数
        >
        > 

      - 生成**随机数（Server Random）**

      然后，服务端为了证明自己的身份，会发送`Server Certificate`给客户端，这个消息里含有数字证书

      随后，服务端发了`Server Hello Done`消息，目的是告诉客户端本次打招呼完毕

  - 客户端验证证书

    - 此处客户端拿到服务端的数字证书之后，会验证该数字证书是否有效

    - #### 数字证书

      **数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充**

      一个数字证书包含：

      - 公钥；
      - 持有者信息；
      - 证书认证机构（CA）的信息；
      - CA 对这份文件的数字签名及使用的算法；
      - 证书有效期；
      - 还有一些其他额外信息；

      

    - #### CA机构

      我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的

      为了让服务端的公钥被大家信任，服务端的证书都是由 CA （*Certificate Authority*，证书认证机构）签名的，CA 就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，那必然证书也是被信任的

      **签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改**

    - #### 数字证书签发和验证流程

      ![image-20221025210802120](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025210802120.png)

      CA签发证书流程：

      - CA会先把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值
      - 然后 **CA 会使用自己的私钥将该 Hash 值加密**，生成 `Certificate Signature`，也就是 CA 对证书做了签名
      - 最后将 `Certificate Signature` 添加在文件证书上，形成数字证书

      客户端校验服务端的数字证书的过程：

      - 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1
      - 通常**浏览器和操作系统中集成了 CA 的公钥信息**，浏览器收到证书后可以使用 CA 的公钥解密 `Certificate Signature` 内容，得到一个 Hash 值 H2 
      - 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信

      

    - #### 证书链

      事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的

      为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题

      

  - TLS第三次握手

    - 客户端验证完证书后，认为可信则继续往下走
    - 客户端就会生成一个新的**随机数 (pre-master)**，**用服务器的 RSA 公钥加密该随机数**，通过`Client Key Exchange`消息传给服务端
    - 服务端收到后，**用 RSA 私钥解密，得到客户端发来的随机数** (pre-master)
    - **客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master**
    - 然后，现在双方都有三个随机数，就都**生成会话密钥，这是对称密钥**，对于后续的HTTP请求和响应的数据加解密
    - 生成完会话密钥后，客户端发一个`Change Cipher Spec`，告诉服务端开始使用加密方式发送消息
    - 然后，客户端再发一个**`Encrypted Handshake Message（Finishd）`**消息，把之前所有发送的数据做个**摘要**，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信**是否可用**和**之前握手信息是否有被中途篡改过**

  - TLS第四次握手

    - 服务器也是同样的操作，发**`Change Cipher Spec`**和**`Encrypted Handshake Message`**消息，**如果双方都验证加密和解密没问题，那么握手正式完成**

      最后，就用**会话密钥**加解密 HTTP 请求和响应了

    

- RSA算法的缺陷

  - **使用 RSA 密钥协商算法的最大问题是不支持前向保密**
  - 因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数
  - 所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解
  - 为了解决这个问题，后面就出现了 ECDHE 密钥协商算法









#### 2.4 混合加密

- **因为非对称加密效率很低，所以有了"混合加密"**

  - 在通信刚开始的时候使用非对称算法，比如RSA、ECDHE，首先解决密钥交换问题
  - 然后用随机数产生对称算法使用的"**会话密钥**"（session key），再用公钥加密。因为会话密钥很短，通常只有16字节或32字节，所以慢一点也无所谓
  - 对方拿到密文后用私钥解密，取出会话密钥。
  - 这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密
  - ![image-20221025213106742](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025213106742.png)
  - d

- 所以通常的做法是，用非对称加密传递对称秘钥，即会话秘钥，用对称加密做数据加密。

- 公钥的来源：

  - 不同秘钥交换方式，公钥来源不同
  - ECDHE，是在每次握手协商的时候都会生成一个临时的公私钥对，交换完会话秘钥后就“扔掉”，不再使用，以实现“前向安全”。
  - 如果是RSA算法，那么公钥是固定的，公钥是服务器的证书里给的，被破解的风险比较大。

- 问题

  - **在混合加密中用到了公钥加密，因为只能由私钥解密。那么反过来，私钥加密后任何人都可以用公钥解密，这有什么用呢？**

    - 这种应用叫数字签名，即证明消息是私钥所有者发布的，对应安全要素中的不可抵赖。

    











### 3.数字签名与证书

- 前面的对称加密和非对称加密以及混合加密，实现了机密性。但是距离安全还是很远
  - 在机密性的基础上加上**完整性、身份认证等特性**，才能实现真正的安全
- 比如黑客可以伪造身份发布公钥，如果你拿到了假的公钥，那么你后续的通信信息就都被窃取了
  - ![image-20221025214536978](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025214536978.png)

#### 3.1 摘要算法

- 实现完整性的手段主要是**摘要算法**（Digest Algorithm），也就是常说的散列函数、哈希函数（Hash Function）

  - 可以把摘要算法近似的理解成一种特殊的压缩算法，**它能够把任意长度的数据"压缩"成固定长度、而且独一无二的“摘要”字符串，就好像给这段数据生成了一个数字“指纹”**
  - 也可以把摘要算法理解成**特殊的"单向"加密算法，它只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文**

- ![image-20221025215850278](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025215850278.png)

- 摘要算法实际上是把数据从一个"大空间"映射到了"小空间"，所以就存在"冲突"（collision，也叫碰撞）的可能性

- **因为摘要算法对输入具有"单向性"和"雪崩效应"， 输入的微小不同会导致输出的剧烈变化，所以也被TLS用来生成伪随机数**

- 目前TLS推荐使用的是SHA-2

  - 特点：对数据进行处理后生成一个定长的字符串，此字符串具有唯一性，**原文微小的变动都会引起字符串剧烈的变动**。【雪崩效应】
  - 流程：**原文+SHA2哈希码加密后传送到接收端，解密后，取得原文和哈希码，对原文进行SHA2哈希计算，结果和原哈希码比较，如果一致则说明原文在传输中没有被篡改。**

  

- 完整性

  - 摘要算法保证了"数字摘要"和原文是完全等价的。所以，**我们只要在原文后附加上它的摘要，就可以保证数据的完整性**
  - **但是摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性**
  - 所以，真正的完整性必须要建立在机密性之上**。在混合加密系统里用会话密钥加密消息和摘要**，这样黑客就无法得知明文了。
    - 这有个术语，叫做**哈希消息认证码（HMAC）**

  - ![image-20221025220529226](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221025220529226.png)








#### 3.2 数字签名

- **使用非对称加密里的"私钥"，使用私钥加上摘要算法，就能够实现"数字签名"，同时实现"身份认证"和"不可否认"**

- 数字签名的原理：**把公钥私钥的用法反过来，之前是公钥加密、私钥解密；现在是私钥加密，公钥解密**

  - 又因为非对称加密效率太低，所以私钥只加密原文的摘要，这样运算量就小得多，而且得到的数字签名也很小，方便保管和传输
  - **签名和公钥一样完全公开**，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，拿到摘要后，再比对原文验证完整性，就可以像签署文件一样证明消息确实是你发的。

- 数字签名和验签原理图：

  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/2021042215181211.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ2MjY4MQ==,size_16,color_FFFFFF,t_70#pic_center)
  - 只要你和网站互相交换公钥，就可以用"签名"和"验签"来确认消息的真实性，因为私钥保密，黑客不能伪造签名，就能够保证通信双方的身份

- 首先要澄清一个概念，数字签名对应与现实世界的签名，是对某文件条款内容的认同。

  - **数字签名及验签过程中传递两样东西，原文和摘要，原文是明文，不加密，摘要要用私钥加密。**

  - 过程是：

    - 上图是原理图，具体到TLS握手，证书通过Certificate消息发送，包括了公钥，有效期等信息【原文】和指纹【数字签名】
    - 发送方根据原文【消息的signedCertificate部分】算出摘要，并用私钥加密，得到数字签名，和原文一同发给对端。
    - 接收方用公钥解密数字签名【消息的encrpted小节】，得到发送方传递过来的摘要
    - 接收方对原文做摘要，并比对2份摘要，如果一致，则证明发送方的身份是公钥的所有者。
    - 注：encrpted是加密的签名而网站上直接查看的指纹是解密后的签名，所以对不上。

  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210422152114528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ2MjY4MQ==,size_16,color_FFFFFF,t_70#pic_center)

    




#### 3.3 数字证书和CA

- 在数字签名之后，还有一个"**公钥的信任**"的问题。

  - 因为谁都可以发布公钥，我们还缺少防止黑客伪造公钥的手段。也就是说，怎么判断这个公钥就是你或者对方的公钥呢？

- 这就要引入一个**公认的可信第三方CA（Certificate Authority，证书认证机构）**。

  - 它就像网络里的公安局、教育部、公证中心，具有极高的可信度，由它来给各个公钥签名，用自身的信誉来保证公钥无法伪造，是可信的

- **CA对公钥的签名认证**也是有格式的

  - 不是简单地**把公钥绑在持有者身份上**就完事了
  - **还要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥关联的各种信息，形成<u>数字证书</u>**

- **数字签名和数字证书**

  - **数字证书是由CA背书并签发的证明文件，包括了<u>被签发者的公钥和版本，签发者，有效期，序列号，用途等信息【原文】，打包后再用CA的私钥签名</u>，以证明被签发者的身份。**
  - 数字签名对应现实世界的签名，签名 者自己证明其有效性，但他人无法确保其真实性。因为签名可以伪造，或当事人有恶意。
  - 数字证书对应现实世界的证书，比如身份证，毕业证，由权威机构背书，证明其真实性，按级别分为DV,EV,OV.

- **证书类别**

  - DV[Domain validated]
    - DV是最低的，只有域名级别的可信
  - OV[organization validated]
  - EV[extended validation]
    - EV是最高的，经过了法律和审计的严格核查，可以证明网站拥有者的身份
  - 三种证书的安全强度是一致的，只是对申请者的审核严格程度逐步加强。

- **CA是怎么证明自己的？**

  - 这还是信任链的问题

  - 小一点的CA可以让大CA签名认证，但链条的最后，也就是**Root CA**，就只能自己证明自己了，这个就叫“**自签名证书**”（Self-Signed Certificate）或者"**根证书**"（Root Certificate）。你必须相信，否则整个证书信任链就走不下去了

  - ![image-20221030142209002](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030142209002.png)

  - **有了这个证书体系，操作系统和浏览器都内置了各大CA的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的**

    

- **证书体系的弱点**

  - 证书体系虽然是目前整个网络世界的安全基础设施，但绝对的安全是不存在的

  - **如果CA失误或者被欺骗，签发了错误的证书，虽然证书是针对，可它代表的网站却是假的**

    - 针对这种情况，开发出了CRL（证书吊销列表，Certificate revocation list）和OCSP（在线证书状态协议，Online Certificate Status Protocol），及时废止有问题的证书

  - **还有一种更危险的情况，CA被黑客攻陷，或者CA有恶意，因为它（即根证书）是信任的源头，整个信任链里的所有证书也都不可信了**

    - 针对这种情况，因为涉及的证书太多，就只能操作系统或者浏览器从根上下手了，撤销对CA的信任，列入黑名单，这样它颁发的所有整数就都会被认为是不安全的

    



#### 3.4 小结

- 摘要算法用来实现完整性，能够为数据生成独一无二的"指纹"，常用的算法是SHA-2

- 数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认

- 公钥的分发需要使用数字证书，必须由CA的信任链来验证，否则就是不可信的

- 作为信任链源头的CA有时也会不可信，解决办法有CRL、OCSP，还有终止信任

- 问题：

  - **为什么公钥能够建立信任链，用对称加密算法里的对称密钥行不行呢？**

    - 不行，对称加密无法解决秘钥传递问题
    - 而公钥的信任链中有个各方都信任的Root Ca，下面有一级，二级CA,证书由CA的私钥保证证书的真实性，上级CA保证下级CA的真实性，如此就建立了一个信任链条。

  - **假设有一个三级的证书体系（Root CA=> 一级 CA=> 二级 CA），你能详细解释一下证书信任链的验证过程吗？—注服务器的证书由二级CA签发。**

    - TLS协商阶段，在交换完Client Hello/Server Hello消息后，**发送方【通常是服务器】，发送Certificate消息，把证书链，包括自己的证书，二级CA证书，一级CA证书，一次性发送给接收方【通常是浏览器】**。
    - 注：每个传递过来的证书包括4部分：
      - signedCertificate签名的证书，即浏览器点击小锁头直观可以看到的证书
      - algorithmIdentifier算法标记，包括了签名证书用到的摘要和签名算法，如sha256WithRSAEncryption
      - Padding填充字符
      - encrpted加密摘要，注：加密摘要不包含在signedCertificate中，所以浏览器中点击小锁头看不到加密摘要【浏览器显示的是解密后的明文的摘要】。
    - 当前接收方只有内置的Root Ca根证书，无法直接信任接收方的证书。**接收方将通过证书链中包含的签发者信息，逐层向上查找直到Root Ca根证书，并从根证书开始，逐级向下做验签。**
      - 首先，用根证书对一级证书做验签。
        - 具体过程是：对一级CA证书【signedCertificate】用传递过来的摘要算法【algorithmIdentifier】做摘要得到摘要1；用Root Ca根证书的公钥解密一级CA证书的数字签名【encrpted】，得到发送过来的摘要2，二者比较，如一致，则认为一级CA证书是真实有效的。
      - 类似的，继续用一级CA证书对二级CA证书做验签，二级CA证书对发送方证书做验签，如果发送方证书验证通过，则随之TLS协商进入Server key exchange阶段。
    - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210422153436155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ2MjY4MQ==,size_16,color_FFFFFF,t_70#pic_center)

  - **整个证书的验证流程是**：

    - 通过Issuer’s–Owner’s获得证书链的所有证书,根证书是内置的，CA,Owner的证书是随Certificate发送的
    - 根证书验证CA
    - CA验证Owner
    - 验证的依据是用上级证书的公钥验证下级证书的签名

    











### 4.TLS1.2连接过程解析

#### 4.1 HTTPS建立连接

- 在HTTP协议里，使用三次握手建立TCP连接后，浏览器会立即发送请求报文
- 但是在HTTPS协议里，它需要再用另外一个"握手"过程，在TCP上建立安全连接，之后才是收发HTTP报文



#### 4.2  TLS协议的组成

- TLS包含几个子协议，也可以理解为**它是由几个不同职责的模块组成**

  - 比较常用的有 记录协议、警报协议、握手协议、变更密码规范协议等

- **记录协议(Record Protocol）**

  - **规定了TLS收发数据的基本单位：记录（record）**
  - 它有点像是TCP里的segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个TCP包里一次性发出，也并不需要像TCP那样返回ACK

- **警报协议（Alert Protocol）**

  - **职责是向对方发出警报信息**，有点像是HTTP协议里的状态码
  - 比如，protocol_version就是不支持旧版本，bad_certificate就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接

- **握手协议（Handshake Protocol）**

  - 是TLS里最复杂的子协议，要比TCP的SYN/ACK复杂的多
  - 浏览器和服务器会在握手过程中协商TLS版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统

- **变更密码规范协议（Handshake Protocol）**

  - **就是一个"通知"，告诉对方，后续的数据都将使用加密保护**
  - 那么反过来。在它之前，数据都是明文的

- 下面这张图简要地描述了TLS的握手过程，其中每一个"框"都是一个记录，多个记录组合成一个TCP包发送。

  - 所以，最多经过两次消息往返（4个消息）就可以完成握手，然后既可以在安全的通信环境里发送HTTP报文，实现HTTPS协议
  - ![image-20221030154524298](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030154524298.png)

- 抓包的准备工作

  - URI为：`/26-1`

  - 为了更好地分析TLS握手过程，可以对系统和Wireshark做一些设置，让浏览器导出握手过程中的秘密信息，这样Wireshark就可以把密文解密，还原出明文

  - 首先，在Windows的设置里新增一个系统变量“**SSLKEYLOGFILE**“，设置浏览器日志文件的路径，比如`D:\http学习\www\temp\sslkey.log`

    - 在设置里搜索"系统变量"，进入后点击"高级"，然后再点击下方"环境变量"，然后点击”新建“
    - ![image-20221030155302681](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030155302681.png)

  - 然后在Wireshark里设置"Protocols-TLS"（较早版本的Wireshark里是"SSL"），在“（Pre）-Master-Secret log filename”里填上刚才的日志文件

    - 上方"编辑"——“首选项”——“Protocols"

    - ![image-20221030155734296](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030155734296.png)

    - 设置好之后，过滤器选择"**tcp prot 443**"，就可以抓到实验环境里的所有HTTPS数据了

      





#### 4.3 ECDHE握手过程

- 解析图：

  - ![image-20221030161505723](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030161505723.png)

    ![image-20221030161514941](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030161514941.png)

- #### 连接过程：

  ##### 第一个消息往返

  - 在TCP建立连接之后，浏览器首先会发一个"**Client Hello**"消息，也就是跟服务器”打招呼“
    - 里面有客户端的版本号、支持的密码套件、还有一个**随机数（Client Random）**，用于后续生成会话密钥
    - 这个的意思就是：我这边有这些信息，你看看哪些是能用的，关键的随机数要留着
  - 服务器收到"Client Hello"后，会返回一个"Server Hello"消息。把版本号对一下，也给出一个**随机数（Server Random）**，然后从客户端的列表里选一个作为本次通信使用的密码套件，这里**假设选择了`TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384`**
    - 里面有随机数，确认TLS的版本号和使用的密码套件
    - 这个的意思就是：版本号对上了，可以加密，我选用一个密码套件`TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384`。我也给你一个随机数，你也得留着
  - 然后，服务器为了证明自己的身份，就把证书也发给了客户端（Server Certificate）
  - 接下来是一个**关键操作**，因为服务器选择了ECDHE算法，所以它会在证书后发送"**Server Key Exchange**"消息，里面是**椭圆曲线的公钥（Server Params）**，用来实现密钥交换算法，再加上自己的私钥签名认证
    - 这相当于说：刚才我选的密码套件有点复杂，所以再给你个算法的参数，和刚才的随机数一样有用，别丢了。为了防止别人冒充，我又盖了个章
  - 之后是"**Server Hello Done**"消息，服务器说：”我的信息就是这些，打招呼完毕“
  - 这样第一个消息往返就结束了（两个TCP包），结果是客户端和服务器通过明文共享了三个信息：**Client Random、Server Random 和Server Params**

  

  ##### 验证证书和双方的参数处理

  - 此时客户端拿到了服务端的证书，开始走证书链逐级验证，确认证书的真实性，再用证书公钥验证签名，就确认了服务器的身份：”刚才跟我打招呼的不是骗子，可以继续接着往下走“
  - 然后，客户端按照密码套件的要求，也生成一个**椭圆曲线的公钥（Client Params）**，用”**Client Key Exchange**“消息发给服务器
    - 现在客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用ECDHE算法算出一个新的东西，叫"**Pre-Master**"，其实也是一个随机数
  - 现在客户端和服务器手里有了三个随机数：**Client Random、Server Random和Pre-Master**。用这三个作为原始材料，就可以生成用于加密会话的主密钥，叫"**Master Secret**"。
    - 而黑客因为拿不到"Pre-Master"，所以也就得不到主密钥
    - Master Secret是怎么来的：
      - 公式：`master_secret = PRF(pre_master_secret,"master secret",ClientHello.random + ServerHello.random)`
      - 这里的"PRF"就是伪随机数函数，它基于密码套件里的最后一个参数，比如这次的SHA384，通过摘要算法来再一次强化"Master Secret"的随机性
    - **主密钥有48字节，但是它也不是最终用于通信的会话密钥，还会用PRF扩展出更多的密钥，比如客户端发送用的会话密钥（client_write_key）、服务器发送用的会话密钥（server_write_key）等等，避免只用一个密钥带来的安全隐患**
  - 有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个"**Change Cipher Spec**"，然后再发一个"**Finished**"消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证
    - 意思就是告诉服务器：”后面都改用对称算法加密通信了啊，用到就是打招呼的时候说的AES，加密对不对还得你测一下“
  - 服务器也是同样的操作，法"**Change Cipher Spec**"和"**Finished**"消息，双方都验证加密解密OK，握手正式结束，后面就收发被加密的HTTP请求和响应了

  



#### 4.4 RSA握手过程

- 上面说的是如今主流的TLS握手过程，与传统的握手有两点不同
  - 第一个，使用ECDHE实现密钥交换，而不是RSA，所以会在服务器端发出"Server Key Exchange"消息
  - 第二个，因为使用了ECDHE，**客户端可以不用等到服务器发回"Finished"确认握手完毕，立即就发出HTTP报文，省去了一个消息往返的时间浪费**。这个叫"**TLS False Start**"，意思就是“抢跑”，和"TCP Fast Open"有点像，都是**不等连接完全建立就提前发应用数据，提高传输的效率**
- 原理图：
  - ![image-20221030171806130](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221030171806130.png)
  - 大体的流程没有变，只是"Pre-Master"不再需要用算法生成，而是客户端直接生成随机数，然后用服务器的公钥加密，通过"**Client Key Exchange**"消息发给服务器。服务器再用私钥解密，这样双方也实现了共享三个随机数，就可以生成主密钥





#### 4.5 双向认证

- 上面说的是"**单向认证**"握手过程，只认证了服务器的身份，而没有认证客户端的身份。
- 为了防止账号、密码被盗，有的时候（比如网上银行）还会使用U盾给用户颁发客户端证书，实现"**双向认证**"，这样会更加安全
- 双向认证的流程也没有太多百脑汇，只是在"**Server Hello Done**"之后，”**Client Key Exchange**“之前，**客户端要发送**"**Client Certificate**"消息，服务器收到后也把证书链走一遍，验证客户端的身份





#### 4.6 小结

- HTTPS协议会先与服务器执行TCP握手，然后执行TLS握手，才能建立安全连接；

- 握手的目标是安全地交换对称密钥，需要三个随机数，第三个随机数"Pre-Master"必须加密传输，绝对不能让黑客破解

- "Hello"消息交换随机数，"Key Exchange"消息交换"Pre-Master"

- "Change Cipher Spec"之前传输的都是明文，之后都是对称密钥加密的密文

  

- 问题：

  - **密码套件里的那些算法分别在握手过程中起了什么作用？**

    - 以TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384为例
    - ECDHE 对称秘钥交换，并根据交换的公钥算出pre-master
    - RSA 提供数字证书的公钥和私钥，并用私钥加密证书摘要。
    - AES_256_GCM 对称加密
    - SHA384 辅助生成对称秘钥；生成秘钥的PRF使用安全套件中指定的摘要算法；证书明文摘要。

  - **你能完整地描述一下 RSA 的握手过程吗？**

    - Client Hello with C,suits,ver
    - Server Hello with S, suit,ver
    - Certificate[Server]
    - Server Hello Done
    - Client Key Exchange
    - RSA public key crypt pre-master
    - Change Cipher spec[client]
    - finished
    - Change Cipher spec[server]
    - finished

    











### 5.TLS1.3特性解析

- TLS1.3 发布于2018年，在保证兼容性的背景下，增强了安全性，提高了性能。

- **兼容性：**

  - 为了兼容大量支持TLS1.2的老旧设备，TLS1.3采用了和1.2一样的报文格式，甚至版本号都伪装成1.2，它通过extension：`support_versions`字段标识其支持1.3。

- **增强安全性：**

  - 所谓增强安全性，就是删除不安全的安全组件，包括对称加密，分组模式，摘要算法，秘钥交换算法，椭圆曲线，只保留了安全的安全组件

  - 对称加密只保留了AES,CHACHA20

  - 分组模式只保留了 AEAD 的GCM、CCM 和 Poly1305

  - 秘钥交换算法，只保留了ECDHE,DHE,1.2里的RSA方式，由于不具备前向安全，就被淘汰了。

  - 摘要算法只能用SHA256、SHA384

  - 椭圆函数只能用P-256和x25519等5种

  - 伪随机数函数由 PRF 升级为 HKDF（HMAC-based Extract-and-Expand Key Derivation Function）

  - 经过删减不安全的安全套件，TLS1.3就不会协商出不安全的安全套件，所以也就比1.2更安全。

  - 现在的TLS1.3中只剩下5个套件：

    - ![image-20221103145644872](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103145644872.png)

    

- **提高性能**：

  - 最直接的变化是由1.2中建立TLS连接需要2-RTT变成现在1-RTT。

    - 具体是：TLS1.3压缩了以前"Hello"协商过程 ，删除了"Key Exchange"消息
      - 客户端在"Client Hello"消息里直接用"**supported_groups**"带上支持的曲线，比如P-256、x25519，用"**key_share**"带上曲线所对应的客户端公钥参数，用"**signature_algorithms**"带上算法签名
      - 服务端在收到后在这些扩展里选定一个曲线和参数，再用"key_share"带上曲线对应的客户端公钥参数，就实现了双方的密钥交换
      - ![image-20221103150130448](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103150130448.png)

  - 握手分析

    - ![image-20221103150241410](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103150241410.png)

      ![image-20221103153811176](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103153811176.png)

    - 在TCP建立连接之后，浏览器首先还是发一个"**Client Hello**"

      - 注意"Client Hello"里的扩展，"**supported_versions**"表示这是TLS1.3，"**supported_groups**"是支持的曲线，"**key_share**"是曲线对应的参数
      - 就相当于说：“还是照老规矩打招呼，这边又这些信息。但我猜你可能会升级，所以再多给你一些东西，也许后面用的是，咱们有话一口气说完"

    - 服务器收到"Client Hello"后同样返回"Server Hello"消息，还是要给出一个**随机数**(Server Random)和选定密码套件

      - 表面上看和TLS1.2是一样的，重点是后面的扩展
      - "**supported_versions**"里确认实验的是TLS1.3，然后在"**key_share**"扩展带上曲线和对应的公钥参数
      - 服务器的"Hello"大概是在说："刚才你给的我都用上了，我再给你几个你缺的参数，这次加密就这么定了"

    - 这时只交换了两条消息，客户端和服务器就拿到了四个共享信息：**Client Random**和**Server Random、Client Params和Server Params**，两边就可以各自用ECDHE算出"**Pre-Master**"，再用HKDF生成主密钥"**Master Secret**"，效率比TLS1.2提高了一大截

    - 在算出主密钥后，服务器立即发出"**Change Cipher Spec**"消息，比TLS1.2提早进入加密通信，后面的证书等就都是加密的了，减少了握手时的明文信息泄露

      - 这里TLS1.3还有一个安全强化措施，多了个"**Certificate Vertify**"消息，用服务器的私钥把前面的曲线、套件、参数等握手数据加了前面，作用和"**Finished**"差不多。但由于是私钥签名，所以强化了身份认证和防篡改

    - 这两个"Hello"消息之后，客户端验证服务器证书，再发"Finished"消息，就正式完成了握手，开始收发HTTP报文

  - 由于剩下的安全套件组合很少，带来的好处是，客户端可以通过extension把所有支持的安全套件及参数在发送Client Hello时就带上，不用再发送消息交互秘钥参数，Server Hello直接根据Client Hello提供的消息，在第一个RTT中就获得了4个参数，C,S,Client key params,Server key params就可以生成pre-master,进而生成master, 并立刻切换到加密传输方式，实现了1-RTT建立TLS连接。同1.2相比，1.3中Server端先切换到密文发送状态，随后发送的Certificate，Certificate Verify,finished是密文传输的。



- 问题：
  - **TLS1.3 里的密码套件如TLS_AES_256_GCM_SHA384 没有指定密钥交换算法和签名算法，那么在握手的时候会不会有问题呢？**
    - TLS1.3的Client Hello extension:signature algorithm携带了签名算法extension:psk_key_exchange_modes秘钥交换算法，服务端可以选择一个，所以不会有问题。
  - **结合上一讲的 RSA 握手过程，解释一下为什么 RSA 密钥交换不具有“前向安全”。**
    - 因为RSA的pre-master是客户端生成的随机数，并用RSA公钥加密，服务端私钥解密获得pre-master，随着时间推移，如果服务器RSA私钥泄露或被破解，则黑客将拿到pre-master,进而获得master秘钥，所有之前用master秘钥加密的消息，将被破解，所以RSA秘钥不具备前向安全。
  - TLS1.3 的握手过程与 TLS1.2 的“False Start”有什么异同？
    - 相同点在于都在一个消息交互后发送业务数据，更具体的说，False Start在Client Change Cipher spec之后，开始客户端发送业务数据。
    - 区别在于，TLS1.3是标准流程，而1.2能否使用false start需要根据秘钥交换的方式，如选择RSA，则无法启动False Start。













### 6.HTTPS的优化

#### 6.1 概括

- HTTPS太慢主要指的是连接慢，而不是使用慢。所以优化的重点集中在连接上。 
  - TLS建立连接的过程中，除了交互消息，还有一些隐性的时间消耗，比如客户端需要验证服务端的证书。
  - TLS握手过程中，客户端验证服务端证书的真伪，有一种情况，证书是真的，但证书已经废弃，或者被加入了黑名单。所以，对于一些重要的网站【chrome的策略是EV证书，mark1无法验证，apple,招行】，除了验证证书真伪，还需要验证证书的有效状态。
  - TLS握手过程中影响性能的部分：
    - ![image-20221103170426809](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103170426809.png)







#### 6.2 软硬件优化

- 硬件优化

  - 硬件优化，说白了就是"花钱"
  - 首先。可以选择**更快的CPU**，最好还内建AES优化，这样既可以加速握手，也可以加速传输
  - 其次，可以选择"**SSL加速卡**"，加解密时调用它的API，让专门的硬件来做非对称加解密，分担CPU的计算压力
  - "**SSL加速服务器**"，用专门的服务器集群来彻底"卸载"TLS握手时的加密解密计算，性能要比单纯的"加速卡"强大得多

- 软件优化

  - 软件方面的优化可以再分成两部分：一个是**软件升级**，一个是**协议优化**

  - 软件升级

    - 实施起来比较简单，就是把现在正在使用的软件尽量升级到最新版本

  - 协议优化

    - 如果有可能，**应当尽量采用TLS1.3**，它大幅度简化了握手的过程，完全握手只要1-RTT，且更加安全

    - 如果暂时不能升级到1.3，只能用1.2，那么**握手时使用的密钥交换协议应当尽量选用椭圆曲线的ECDHE算法**。

    - **椭圆曲线也要选择高性能的曲线**，最好是x25519，次优选择是P-256。

    - 对称加密算法也可以选用"AES_128_GCM"，比"AES_256_GCM"快一点

    - **在Nginx里可以用"ssl_ciphers"、”ssl_ecdh_curve“等指令配置服务器使用的密码套件和椭圆曲线，把优先使用的放在前面**

      - 如：

        ```js
        ssl_ciphers    TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:EECDH+CHACHA20;
        ssl_ecdh_curve        		x25519:P-256;
        ```

      





#### 6.3 证书优化

- 除了密钥交换，握手过程中的证书验证也是一个比较耗时的操作，**服务器需要把自己的证书链全部发给客户端，然后客户端接收后再注意验证**
- 这里有两个优化点，一个是**证书传输**，一个是**证书验证**
- 客户端的证书验证除了要**公钥解密验证多个证书签名**外，因为证书还有可能会被撤销失效，**客户端有时还会再去访问CA，下载CRL或者OCSP数据**，这又会产生DNS查询、建立连接、收发数据等一系列网络通信，增加好几个RTT
  - 其中**CRL是指被废弃的证书列表**，CRL需要客户端下载一个废弃证书列表，通常有几兆，代价很大，已淘汰。
  - **OCSP在线证书状态协议（Online Certificate Status Protocol）指在线查询证书状态**。 客户端在线连接到CA验证，有额外的RTT消耗。
  - **OCSP Stapling（OCSP装订）**，OCSP的改进**，由服务端预先查询CA，在Server Hello消息中随着证书一起返回给客户端**。
  - 另外是**证书传输和计算，建议选择椭圆曲线证书（ECDSA）**，因为224位ECC加密强度相当于2048位RSA，传输ECC证书节省带宽，验证证书的计算量也比较小。







#### 6.4 会话复用

- TLS握手的重点是算出主密钥"Master Secret"，而主密钥每次连接都要重新计算。如果能将主密钥缓存一下"重用"，就可以免去了握手和计算的成本了。这种做法就叫做"**会话复用（TLS session resumption）**"

- 会话复用分两种，一种叫做"**Session ID**"，另一种叫做"**Session Ticket**"

- **Session ID**

  - 就是客户端和服务器首次连接后各自保存一个会话的ID号，内存里储存主密钥和其他相关的信息。当客户端再次连接发一个ID过来，服务器就在内存里找，找到就直接用主密钥恢复会话状态，跳过证书验证和密钥交换，只用一个消息往返就可以建立安全通信

  - 服务器在"Server Hello"消息后就直接发送了"Change Cipher Spec"和"Finished"消息，省略去了计算主密钥的步骤

    - ![image-20221103191336330](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103191336330.png)

    

- **Session Ticket（会话票证）**

  - 有点类似于HTTP的Cookie，存储的责任由服务器转移到了客户端，服务器加密会话信息，用"New Session Ticket"消息发给客户端，让客户端保存

  - 重连的时候，客户端使用扩展"**session_ticket**"发送"Ticket"而不是"Session ID"，服务器解密后验证有效期，就可以恢复会话，开始加密通信

  - 不过"Session Ticket"方案**需要使用一个固定的密钥文件（ticket_key）来加密Ticket**，为了防止密钥被破解，保证"前向安全"，密钥文件需要定期轮换，比如设置为一小时或者一天

    

- **预共享密钥**

  - "False Start"、"Session ID"、"Session Ticket"等方式只能直线1-RTT，而TLS1.3更进一步实现了"**0-RTT**"

  - 原理和"Session Ticket"差不多，但在发送Ticket的同时会带上应用数据（Early Data），免去了1.2里的服务器确认步骤，这种方式叫"**Pre-shared Key**"，简称为"PSK"

  - ![image-20221103192441168](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221103192441168.png)

    

- 问题

  - **你能比较一下“Session ID”“Session Ticket”“PSK”这三种会话复用手段的异同吗？**
    - Session ID, Session Ticket, PSK都是TLS连接协议优化手段。
    - 不同的是Session ID, Session Ticket可以实现1-RTT,PSK可以实现0-RTT。
    - Session ID和Session Ticket的区别是，使用Session ID方式，压力在服务器端，服务器在内存里保存Session ID,收到Client Hello并检索Session ID，恢复会话
    - Session Ticket方式类似cookie,服务器发送new Session ticket,客户端保存，连接时客户端发送Session ticket,服务器解密恢复会话。











### 7.应该迁移到HTTPS吗

- HTTPS的潮流无法阻挡，应该迁移

- **申请证书**

  - 要把网站从HTTP切换到HTTPS，首先要做的就是为网站申请一张证书
  - 可以向传统的CA申请证书，如DigiCert、GlobalSign，也可以使用"Let's Encrypt"这样的免费证书
    - "**Let' s Encrypt**"一直在推动证书的自动化部署，为此实现了专门的ACME协议。
    - 很多客户端软件可以完成申请、验证、下载、更新的一条龙操作，比如Certbot、acme.sh等
  - 注意事项
    - 申请证书时**应当同时申请RSA和ECDSA两种证书**，在Nginx里配置成双证书验证，这样服务器可以自动选择快速的椭圆曲线证书，同时也兼容只支持RSA的客户端
    - **如果申请RSA证书，私钥至少要2048位，摘要算法一共选用SHA-2**，例如SHA256、SHA384等
    - 出于安全的考虑，"Let' s Encrypt"证书的有效期很短，只有90天，时间一到就会过期失效，所以**必须要定期更新**。
      - 可以在crontab里加个每周或每月认为，发送更新请求，不过很多ACME客户端会自动添加这样的定期任务

- **配置HTTPS**

  - 基本配置

    - 在Nginx上的`listen`指令后面加上参数"ssl"，再配上刚才的证书文件就可以实现最基本的HTTPS

      ```js
      listen        443 ssl;
      
      ssl_certificate           xxx_rsa.crt;  #rsa2048 cert
      ssl_certificate_key       xxx_rsa.key;  #rsa2048 private key
      
      ssl_certificate           xxx_ecc.crt;  #ecdsa cert
      ssl_certificate_key       xxx_ecc.key;  #ecdsa private key
      ```

      

  - 服务器名称指示

    - 在HTTP协议里，多个域名可以同时在一个IP地址上允许，这就是"虚拟主机"，Web服务器会使用请求头里的Host字段来选择

    - 但在HTTPS里，因为请求头只有在TLS握手之后才能发送，在握手时就必须选择"虚拟主机"对应的证书，TLS无法得知域名的信息，就只能用IP地址来区分。所以，最早的时候每个HTTPS域名必须使用独立的IP地址，非常不方便

      - 如何解决这个问题？——用TLS的"扩展"，给协议加个**SNI**（Server Name Indication）的"补充条款"。

      - 它的作用和Host字段差不多。客户端会在"Client Hello"时带上域名信息，这样服务器就可以根据名字而不是IP地址来选择证书

        ```js
        Extension: server_name (len=19)
            Server Name Indication extension
            	Server Name Type: host_name(0)
        		Server Name: www.chrono.com
        ```

      

  - 安全性能配置

    - **强制Nginx只支持TLS1.2以上的协议**，**打开"Session Ticket"会话复用**：

      ```js
      ssl_protocols                     TLSv1.2 TLSv1.3
      
      ssl_session_timeout               5m;
      ssl_session_tickets               on;
      ssl_session_ticket_key            ticket.key;
      ```

    - **以服务器的套件优先**。这样**可以避免恶意客户端故意选择较弱的套件、降低安全等级**，然后密码套件向TLS1.3看齐，**只使用ECDHE、AES和ChaCha20，支持"False Start"**

      ```js
      ssl_prefer_server_ciphers    on;
      
      
      ssl_ciphers      ECDHE-ECHSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128
      ```

      

  - 重定向跳转

    - 现在有了HTTPS服务，但原理的HTTP站点也不能马上弃用，还是会有很多人习惯敲域名默认使用HTTP访问

    - 所以，就需要把不安全的HTTP网址用301或302"重定向到新的HTTPS网址

    - 这在Nginx里使用"return"或"rewrite"都可以做到：

      ```js
      return 301 https://$host$request_uri;     #永久重定向
      rewrite ^ https://$host$request_uri permanent;     #永久重定向
      ```

    - 但**这种方式有两个问题**

      - 一个是重定向增加了网络成本，多出来一次请求
      - 另一个是存在安全隐患，重定向的响应可能会被"中间人"篡改，实现"会话劫持"，跳转到恶意网站 

      

    - 所以有一种叫"**HSTS**"（HTTP严格传输安全，HTTP Strict Transport Security）的技术可以消除这种隐患

      - HTTPS服务器需要在发出的响应头里添加一个"**Strict-Transport-Security**"的字段，再设定一个有效期，例如

        ```js
        Strict-Transport-Security: max-age=15768000; includeSubDomains
        ```

      - 这相当于告诉浏览器：我这个网站必须严格使用HTTPS协议，在半年之内（182.5天）都不允许用HTTP，你以后就自己做转换吧

      - 有了"HSTS"的指示，**以后浏览器再访问同样的域名的时候就会自动把URI里的"http"改成"https"，直接访问安全的HTTPS网站**。这样"中间人"就失去了攻击的机会，而且对于客户端来说也免去了一次跳转，加快了连接速度

  - 全部配置完成后，可以访问`SSLLabs`网站，测试网站的安全程度，它会模拟多种客户端发起测试，打出一个综合的评分

    

















## 五.飞翔篇

### 1.HTTP/2特性概览

- 为什么不是HTTP/2.0

  - HTTP/2的前身是GOOGLE研发的SPDY协议，经过IETF的规范，目前的标准是RFC7540。
  - HTTP/2的命名不是HTTP/2.0，它摒弃了小版本号，以后只有HTTP/2,HTTP/3。这是**因为HTTP是互联网基础技术，版本的进化需要相对的稳定性，频繁的版本变容易造成混乱**。

- 兼容 HTTP/1

  - 因为有大量现有资源基于HTTP/1，所以必须要兼容HTTP/1。HTTP/2在URI层面，没有引入新的scheme，还是http和https。
  - 另外，**把HTTP分为语义和语法2部分**，语义方面如请求/应答模式，URI，状态码，头字段等概念仍沿用HTTP/1，消除了学习成本，上层应用无需修改，即可无缝移植。
  - 但具体的底层实现则不同，甚至差别很大，比如采用了二进制编码，取消了版本号，引入了流，帧等概念。

- 头部压缩

  - HTTP/2中引入`HPACK算法`**对头部进行压缩**。
  - **压缩的必要性**：HTTP头部通常很大，而实体很小，尤其是GET方法。例如，实例：30-1，头部有530个字符，而实体只有94个字符。
  - 具体实现：HPACK，**两端建立字典，用索引替代头字段，并对数字，字符采用哈夫曼编码，大幅减少了需要传输的头字段字节数，并随着时间的推移，字典复用率越高，压缩效果越好**。
  - 如何同步字典是个问题。

- 二进制格式

  - HTTP/2中消息格式采用二进制方式，易于计算机实现，消除ASCII码明文消息带来的歧义和处理复杂性。

  - 另外采用二进制编码需要的字节数也更少，比如数字10000,采用ASCII编码，需要5个字节，而二进制编码只需2个字节。

  - 以二进制格式为基础，HTTP/2开始了改革

    - 他把TCP协议的部分特性挪到了应用层，把原来的"Header+Body"的消息"打散"为数个小片的**二进制"帧"**（Frame），用"HEADERS"帧存放头数据、"DATA"帧存放实体数据

    - 这种做法有点像是"Chunked"分块编码的方式，也是"化整为零"的思路，但HTTP/2数据分帧后"Header+Body"的报文结构就完全消失了，协议看到的只是一个个碎片

    - ![image-20221104155234111](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221104155234111.png)

      

- 虚拟的“流”

  - 消息的碎片到达目的地后该怎样组装起来？
    - HTTP/2为此定义了一个"**流**"（Stream）的概念，**它是二进制帧的双向传输序列**，同一个消息往返的帧会分配一个唯一的流ID
    - 可以把它看成是一个虚拟的"数据流"，在里面流动的是一串有先后顺序的数据帧，这些数据帧按照次序组装起来就是HTTP/1里的请求报文和响应报文
  - **多路复用**：多路指的是虚拟的流，复用是指复用同一个TCP连接。
  - HTTP/2中引入了流，帧等概念，实现多路复用，消除了HTTP层面的头部阻塞。
  - HTTP/2中的消息，流和帧的关系：
    - HTTP/2中主要的工作逻辑还是收发模式，一条HTTP/2消息，从用户角度看，对应一次HTTP请求或回应。
    - 从实现角度看，一条消息对应一个流，流由若干个帧组成，用ID标识帧所属的流，每个帧是消息的一部分，是流的具体实现，所以说HTTP/2中的流是虚拟的。
    - ![image-20221104155921171](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221104155921171.png)
  - HTTP/2还在一定程度上改变了传统的"请求-应答"工作模式，服务器不再是完全被动地响应请求，也可以新建"流"主动向客户端发送消息。
    - 比如，在浏览器刚请求HTML的时候就提前把可能会用到的JS、CSS文件发给客户端，减少等待的延迟，这被称为"**服务器推送**"（Server Push，也叫Cache Push）

- **强化安全**

  - 互联网上通常所能见到的HTTP/2都是使用"https"协议名，跑在TLS上面的
  - 为了区分"加密"和"明文"这两个不同的版本，HTTP/2协议定义了两个字符串标识符
    - "**h2**"表示加密的HTTP/2
    - "**h2c**"表示明文的HTTP/2，多出的那个字母"c"的意思是"clear text"
  - 采用TLS1.2+,强化了安全性

- **协议栈**

  - 对比HTTP/1、HTTPS和HTTP/2的协议栈：
    - ![image-20221104162014711](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221104162014711.png)
  - 基于TCP/TLS1.2+,实现了HPACK和Stream

  

- 问题

  - **你觉得明文形式的 HTTP/2（h2c）有什么好处，应该如何使用呢？**

    - HTTP/2 h2c明文形式方便内部学习，培训，或内部对于安全性要求不高的情况。
    - 注：HTTP/2 h2c建立连接时协商升级过程和HTTP/2是不同的。
      - HTTP/2 h2使用的是TLS的ALPN，而HTTP/2 h2c使用的是connection和upgrade头字段。

  - **你觉得应该怎样理解 HTTP/2 里的“流”，为什么它是“虚拟”的？**

    - HTTP/2的流对应于HTTP中的消息，但TCP上传递的不是流而是帧，帧是消息的片段，用流ID标记帧属于哪个流，从逻辑上看，仿佛由帧构成的若干的流在服务端客户端之间流动，所以流是虚拟的。

  - **你能对比一下 HTTP/2 与 HTTP/1、HTTPS 的相同点和不同点吗？**

    - 相同点，它们都是web服务的重要支撑技术，负责数据的点到点传输。
    - 区别：
      - HTTP/1明文，无安全性，性能不足，有队头阻塞问题。
      - HTTPS 相对HTTP/1增加了安全性，其它一样。
      - HTTP/2相对HTTPS，提高了性能，解决了HTTP层面的队头阻塞问题，服务器可以主动推送数据。
      - 提升性能是通过压缩头字段
      - 解决HTTP队头阻塞是通过引入流和帧，虚拟的流通过TCP收发，某个流的阻塞不会影响其它流的收发，故而解决了HTTP队头阻塞问题。

    











### 2.HTTP/2内核剖析

#### 2.1 连接前言

- 由于HTTP/2事实上是基于TLS，所以在正式收发数据之前，会有TCP握手和TLS握手。

- TLS握手成功之后，客户端必须要发送一个"**连接前言**"（connection preface），**用来确认建立HTTP/2连接了，意思是以后的消息切换到HTTP/2**

  - 这个**"连接前言"是标准的HTTP/1请求报文，使用纯文本的ASCII码格式，请求方法是特别注册的一个关键字"PRI"，全文只有24个字节**：

    ```js
    PRI * HTTP/2.0\r\n\r\nSM\n\r\n
    ```

  - 在Wireshark里，HTTP/2的"连接前言"被称为"**Magic**"





#### 2.2 头部压缩

- 确立了连接之后，HTTP/2就开始准备请求报文
- HTTP/2的**消息结构还是"Header+Body"**，只不过细节有了变化，
  - 在请求发送前，必须要用"**HPACK**"算法来压缩头部数据
    - **"HPACK"算法是专门为压缩HTTP头部定制的算法，与gzip、zlib等压缩算法不同，它是一个"有状态"的算法，需要客户端和服务器各自维护一份"索引表"，也可以说是"字典"，压缩和解压缩就是查表和更新表的操作**
  - **去掉了HTTP/1中的起始行，所有头字段统一用键值对表示**，原来起始行的请求方法，URI，状态码等，转化为`key: value`的形式，称为**伪头字段**。
    - 伪头字段共有五个：`:authority`（域名），`:method`（请求方法），`:scheme`，`:path`，`:status`（状态码）
- HTTP/2**为一些最常用的头字段**定义了一个**只读**的"**静态表**"（Static Table）
  - 下面是一个"静态表"的一部分
    - 比如"2"代表"GET"，"8"代表状态码200
    - ![image-20221104212050820](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221104212050820.png)
  - 注：HTTP/2头字段要求小写

- 如果表中只有Key没有Value，或者是自定义字段，根本找不到。这时候就要用到"**动态表**"（Dynamic Table）

  - 它添加在静态表后面，结构相同，但会在编码解析的时候随时更新
  - 比如：第一次发送请求时的"user-agent"字段长是一百多个字节，用哈夫曼压缩编码发送之后，客户端和服务器都更新自己的动态表，添加一个新的索引号"65"。那么下一次发送的时候就不用再重复发那么多字节了，只要用一个字节发送编号就好
  - ![image-20221104213026608](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221104213026608.png)

  

  

  



#### 2.3 二进制帧

- 头部压缩数据后，HTTP/2就要把报文**拆成二进制的帧**准备发送
- HTTP/2的帧结构类似TCP的段或者TLS中的记录，但报头很小，只有9字节
  - 且二进制的格式也保证了不会有歧义，使用位运算能够简答高效地解析
  - ![image-20221105172211083](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105172211083.png)
  - 帧开头是**3个字节的长度**（但不包括头的9个字节）
    - 默认上限是2^14^,最大是2^24^，也就是说**HTTP/2的帧通常不超过16K，最大是16M**
  - 长度后面一个字节是**帧类型**，大致可以分成**数据帧**和**控制帧**两类，
    - HEADERS帧和DATA帧属于数据帧，存放的是HTTP报文
    - SETTINGS、PING、PRIORITY等则是用来管理流的控制帧
    - HTTP/2总共定义了10种类型的帧，但一个字节可以表示最多256种，所以**也允许在标准之外定义其他类型实现功能扩展**
  - 第5个字节是非常重要的**帧标志**信息
    - 可以保存8个标志位，携带简单的控制信息
    - 常用的标志位有**END_HEADERS**表示**头数据结束，相当于HTTP/1里后面的空行("\r\n)"**
    - **END_STREAM**表示**单向数据发送结束（即EOS,End of Stream），相当于HTTP/1里Chunked分块结束标志("0\r\n\r\n")**
  - 报文头里最后 4个字节是**流标识符**
    - 也就是**帧所属的"流"**，接收方使用它就可以从乱序的帧里识别出具有相同流ID的帧序列，按顺序组装起来就实现了虚拟的"流"
    - 流标识符虽然有4个字节，但最高位被保留不用，所以只有31位可以使用。也就是说，流标识符的上限是2^31^
    - 通常客户端发起的流编号为奇数，服务端发起的流编号为偶数
    - 流是双向的，同一对请求响应消息共用一个流编号，所以一个流对应一次请求应答。
- 抓包实例
  - ![image-20221105174526384](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105174526384.png)
  - 在这个帧里，开头的三个字节是"00010a"，标识数据长度是266字节
  - 帧类型是1，标识HEADERS帧
  - 标志位是0x25，转换成二进制有3个位被置1。PRIORITY表示设置了流的优先级，END_HEADERS表示这一个帧就是一个完整的头数据，END_STREAM表示单方向数据发送结束，后续不会再有数据帧（即请求报文完毕，不会再有DATA帧/Body数据）
  - 最后4个字节的流标识符是整数1，标识这是客户端发起的第一个流，后面的响应数据帧也会是这个ID，也就是说在stream[1]里完成这个请求响应







#### 2.4 流与多路复用

- **流是二进制帧的双向传输序列**

  - 在HTTP/2连接上，虽然帧是乱序收发的，但只要它们都拥有相同的流ID，就都属于一个流。而且在这个流里帧不是无序的，而是有严格的先后顺序
  - 在概念上，一个HTTP/2的流就等同于一个HTTP/1里的"请求-应答"。

- **HTTP/2的流的特点**

  - **流是可并发的，一个HTTP/2连接上可以同时发出多个流传输数据，也就是并发多请求，实现"多路复用"**

    - 如果HTTP/2在一个连接上使用多个流收发数据，那么它本身默认就会是长连接，所以用于不需要"Connection"头字段（keepalive 或close）

  - 客户端和服务器都可以创建流，双方互不干扰

  - 流是双向的，一个流里面客户端和服务器都可以发送或接收数据帧，也就是一个"请求-应答"来回

  - 流之间没有固定关系，彼此独立，但流内部的帧是有严格顺序的

  - 流可以设置优先级，让服务器优先处理，比如先传HTML/CSS，后传图片，优化用户体验

  - 流ID不能重用，只能顺序递增，客户端发起的ID是奇数，服务器发起的ID是偶数

    - ID用完了怎么办？ —— 这时可以再发一个控制帧"GOAWAY"，真正关闭TCP连接

  - 在流上发送"RST_STREAM"帧可以随时终止流，取消接收或发送

  - 第0号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧，用于流量控制

  - ![image-20221105185846096](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105185846096.png)

    

- 流状态转换

  - 流的状态转换图

    ![image-20221105191530798](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105191530798.png)

  - 最开始的时候流都是"**空闲(idle)**"状态，也就是"不存在"，可以理解成是待分配的"号段资源"

  - 当客户端发送HEADERS帧后，有了流ID，流就进入了"**打开（oepn）**"状态

    - 两端都可以收发数据

  - 然后**客户端**发送一个带"END_STREAM"标志位的帧，流就进入了"**半关闭（half closed）**"状态

    - 这个"半关闭"状态意味着**客户端的请求数据以及发送完了，需要接受响应数据，而服务器端也知道请求数据接受完毕，之后就要内部处理，再发送响应数据**

  - 响应数据发完了之后，也要带上"END_STREAM"标志位，表示数据发送完毕，这样流两端就都进入了"**关闭（closed）**"状态，流就结束了

  - **流ID不能重用，所以流的生命周期就是HTTP/1里的一次完整的"请求-应答"，流关闭就是一次通信结束**

  - 下一次再发请求就要开一个新流（而不是新连接），流ID不断增加，直到达到上限，发送"GOAWAY"帧开一个新的TCP连接，流ID就又可以重新计数

    

- 问题

  - **HTTP/2 的动态表维护、流状态转换很复杂，你认为 HTTP/2 还是“无状态”的吗？**

    - HTTP/2还是无状态的,动态表维护不过是为HPACK服务，目的是减少收发的数据。
    - 流状态转换不过是一次收发的控制，和HTTP/2是否有状态没有关系。
    - HTTP/2并没有引入机制记录会话状态。

  - **HTTP/2 的帧最大可以达到 16M，你觉得大帧好还是小帧好？**

    - 看应用场景，如果网络质量好，则帧大好，反之小帧好。

  - **结合这两讲，谈谈 HTTP/2 是如何解决“队头阻塞”问题的**。

    - 通过虚拟流和帧解决HTTP层面的队头阻塞。一个虚拟流相当于一次HTTP请求应答，多个流可以并发，相互不受影响，故而没有队头阻塞问题。

    









### 3.HTTP/3展望

#### 3.1 HTTP/2的"队头阻塞"

- HTTP/2的头部压缩、二进制分帧、虚拟流与多路复用，基本上解决了队头阻塞的问题
- 但为什么是基本上而不是完全解决呢？
  - 这是因为HTTP/2虽然使用"帧"、"流"、"多路复用"，没有了"队头阻塞"，但这些手段都是在应用层里，而在下层，也就是TCP协议里，还是会发生"队头阻塞"
- TCP为了保证可靠传输，有个"丢包重传"机制，丢失的包必须要等待重新传输确认，其他的包即使已经收到了，也只能放在缓冲区里，上层的应用拿不出来
  - 由于这种"队头阻塞"是TCP协议固有的，所以HTTP/2设计出再多方法也无法解决
- 因此Google就发明了一个新的"QUIC"协议，让HTTP跑在QUIC上而不是TCP上
  - 而这个"HTTP over QUIC"就是HTTP协议的下一个大版本，**HTTP/3**
- HTTP/3的协议栈图
  - ![image-20221105195605424](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105195605424.png)





#### 3.2 QUIC协议

- 在上图中，可以看到HTTP/3**把下层的TCP抽掉了，换成了UDP**。因为UDP是无序的，包之间没有依赖关系，所以就从根本上解决了"队头阻塞"

- QUIC协议集成了TLS，并实现了类似HTTP/2的多路复用，流管理，彻底解决了HTTP的队头拥塞问题。

- QUIC的特点

  - QUIC基于UDP，而UDP是“无连接”的，根本就不需要"握手"和"挥手"，所以天生就要**比TCP快**
  - 就像TCP在IP的基础上实现了可靠传输一样，**QUIC也基于UDP实现了可靠传输**，保证数据一定能抵达目的地。
  - 还引入了类似HTTP/2的"流"和"多路复用"，**单个"流"是有序的，可能因为丢包而阻塞，但其"流"不会受到影响**
  - QUIC直接应用TLS1.3，获得了0-RTT、1-RTT连接的好处
  - **QUIC并不是建立在TLS之上，而是内部"包含"了TLS**。
    - 它使用自己的帧"接管"了TLS里的"记录"，握手消息、警报消息都不使用TLS记录，直接封装成QUIC的帧发送，省掉了一次开销

- QUIC内部细节

  - QUIC的基本数据传输单位是**包**（packet）和**帧**（frame），一个包由多个帧组成，包面向的是"连接"，帧面向的是"流"

  - QUIC使用不透明的"**连接ID**"来标记通信的两个端点，客户端和服务器可以自行选择一组ID来标记自己，这样就解除了TCP里连接对"IP地址+端口"（即常说的四元组）的强绑定，支持"**连接迁移**"（Connection Migration）

    - 比如当手机从4G切换到WiFi时，IP地址会发生变化，TCP就必须重新建立连接。
    - 而QUIC连接里的两端连接ID不会变，所以连接在"逻辑上"没有中断，它就可以在新的IP地址上继续使用之前的连接，消除重连的成本，实现连接的无缝迁移

  - ![image-20221105202459276](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105202459276.png)

  - QUIC的帧有多种类型

    - PING、ACK等帧用于管理连接
    - 而STREAM帧专门用来实现流

  - QUIC里的流与HTTP/2的流非常相似，**也是帧的序列**

    - 但HTTP/2里的流是双向的，而**QUIC则分为双向流和单向流**

  - QUIC帧普遍采用变长编码，最少只要1个字节，最多有8个字节。

    - ![image-20221105203729855](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105203729855.png)

    - 流ID的最大可用位数是62，最低两位是标记位。数量上比HTTP/2的2^31^大大增加

      - xxxx00 双向流客户端发起
      - xxxx01 双向流服务端发起
      - xxxx10 单向流客户端发起
      - xxxx11 单向流服务端发起

    - **流ID**还保留了**最低两位用作标志**，**第1位标记流的发起者，0表示客户端，1表示服务器；第2位标记流的方向，0表示双向流，1表示单向流**

    - 所以**QUIC流ID的奇偶性质与HTTP/2刚好相反，客户端的ID是偶数，从0开始计数**

      





#### 3.3 HTTP/3协议

- 因为QUIC本身就已经支持了加密、流和多路复用，所以HTTP/3把流控制都交给QUIC去做，调用的是专门的QUIC函数

  - 不过这个"QUIC函数"还没有形成标准，必须要绑定到某一个具体的实现库

- **HTTP/3**里仍然使用流来发送"请求-响应"，但它自身不需要像HTTP/2那样再去定义流，而是**直接使用QUIC的流，相当于做了一个"概念映射"**

- HTTP/3里的**“双向流”可用完全对应到HTTP/2里的流**，而**"单向流"在HTTP/3里用来实现控制和推送，近似地对应HTTP/2里的0号流**

- HTTP/3里帧的结构

  - 帧头只有两个字段：**类型和长度**，而且同样采用**变长编码**，最小只需要两个字节
  - ![image-20221105210335872](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105210335872.png)
  - HTTP/3里的帧仍然分成**数据帧和控制帧**两类
    - HEADERS帧和DATA帧传输数据
    - 但其他一些帧因为在QUIC里有了替代，所以在HTTP/3里就消失了，比如RST_STREAM、WINDOW_UPDATE、PING等
  - **头部压缩算法**在HTTP/3里升级成了"**QPACK**"，使用方式上也发生改变
    - 虽然也分成静态表和动态表，但**在流上发送HEADERS帧时不能更新字段，只能引用**
    - **索引表的更新需要在专门的单向流上发送指令来管理，解决了HPACK的"队头阻塞"问题**
    - QPACK的字典也做了优化，**静态表由原来的61个增加到了98个，而且序号从0开始，也就是说":authority"的编号是0**

- **HTTP/3没有指定默认的端口号**，那么该怎么"发现"HTTP/3呢？

  - 这里要用到HTTP/2里的"扩展帧"

  - **浏览器需要先用HTTP/2协议连接服务器，然后服务器可以在启动HTTP/2连接后发送一个<u>"Alt-Svc"帧</u>，包含一个"h3=host:port"的字符串，告诉浏览器在另一个端点提供等价的HTTP/3服务**

  - 浏览器收到"Alt-Svc"帧，会**使用QUIC异步连接指定的端口，如果连接成功，就会断开HTTP/2连接，改用新的HTTP/3收发数据**

    

- 问题

  - **IP 协议要比 UDP 协议省去 8 个字节的成本，也更通用，QUIC 为什么不构建在 IP 协议之上呢？**

    - QUIC是个专用协议，只针对HTTP服务，其它应用用不了，感觉还是建立在UDP上比较好，QUIC应该可以建立在IP协议上，不知道协议设计者是怎么考虑的。

  - **说一说你理解的 QUIC、HTTP/3 的好处。**

    - 使用TLS1.3+，彻底解决了HTTP队头阻塞问题，支持连接迁移，QPACK解决HPACK队头阻塞问题。

  - **对比一下 HTTP/3 和 HTTP/2 各自的流、帧，有什么相同点和不同点。**

    - 相同：都用流+frame+多路复用的方式，解决了HTTP层面的队头阻塞
    - 不同：HTTP/3基于QUIC，还解决了TCP导致的队头阻塞。

    









### 4.应该迁移到HTTP/2吗

- **HTTP/2的优点**

  - **兼顾安全和性能**，同时**语义完全兼容HTTP/1**，上层应用无需修改，就可以运行在HTTP/2上。
    - 安全：TLS1.2+
    - 性能：HPACK报头压缩
    - 解决问题：HTTP队头阻塞
  - HTTP基于请求-响应工作模式，它是**半双工且串行**的，对于HTTP/1而言，一个TCP连接资源利用率很低。所以HTTP/1中，一个域名会最多并发6个连接。**HTTP/2中，一个域名对应一个TCP连接，利用<u>多路复用</u>多个请求应答流并行，<u>提高了TCP连接的利用率</u>。**
  -  另外配合**流的优先级调度，服务器推送，HAPCK字典积累**，综合HTTP/2的资源利用率，效率更高。
    - ”**优先级“可以让客户端告诉服务器，哪个文件更重要，更需要优先传输**，服务器就可以调高流的优先级，合理的分配有限的带宽资源，让高优先级的HTML、图片更快地到达客户端，尽早加载显示
    - **"服务器推送"也是降低延迟的有效手段，它不需要客户端预先请求，服务器直接就发给客户端，这就省去了客户端解析HTML再请求的时间**

- **HTTP/2的缺点**

  - 它的缺点是，一些针对HTTP/1的前端优化技术，反而有负面效果：比如精灵图，资源内联，域名分片等。
  - HTTP/1并发多个TCP连接，断开某个连接，其它不受影响。
  - HTTP/2一个域名只对应一个TCP连接，一旦重建TCP连接，全站HTTP连接受影响，**积累的HPACK需要重新生成**，代价比HTTP/1大。

- **应该迁移到HTTP/2吗**

  - 因为HTTP/2的侧重点是"性能"，所以"是否迁移"就需要在这方面进行评估
    - 如果网站的流量很大，那么HTTP/2就可以带来可观的收益
    - 如果网站流量比较小，那么升级到HTTP/2就没有太多必要了

- **配置HTTP/2**

  - 如果已经迁移到了HTTPS，那么在Nginx中启用HTTP/2只需要**在server 配置里再多加一个参数就可以了**

    - ```js
      server {
          listen              443 ssl http2;
          
          
          server_name         www.xxx.net;
          
          
          ssl_certificate         xxx.crt;
          ssl_certificate_key     xxx.key;
      }
      ```

    - 注意"listen"指令，在"ssl"后面多路一个"http2"，这就表示在443端口上开启了SSL加密，然后再启用HTTP、2

  - **配置服务器推送特性**可以使用指令`http2_push`和`http2_push_preload`

    ```js
    http2_push          /style/xxx.css;
    http2_push_preload on;
    ```

  - HTTP/2**默认启用header压缩（HPACK），但没有默认启用body压缩**，所以要在Nginx配置文件里加上"gzip"指令，压缩HTML、JS等文本数据

- **应用层协议协商(ALPN)**

  - 在URI里用到都是HTTPS协议名，没有版本标记，浏览器怎么直到服务器支持HTTP/2呢？
    - 在TLS的扩展里，有一个叫"**ALPN**"（Application Layer Protocol Negotiation）的东西，**用来与服务器就TLS上跑的应用协议进行"协商"**
  - 客户端在发起"Client Hello"握手的时候，后面会带上一个"ALPN"扩展，里面按照优先顺序列出客户端支持的应用协议
    - ![image-20221105213711189](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105213711189.png)
    - 上图最优先的是"h2"，其次是"http/1.1"
  - 服务器看到ALPN扩展以后就**可以从列表里选择一种应用协议**，**在"Server Hello"里也带上"ALPN"扩展，告诉客户端服务器据欸的那个使用的是哪一种**
    - ![image-20221105213939616](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221105213939616.png)
  - 这样在TLS握手结束后，客户端和服务器就通过"ALPN"完成了应用层的协议协商，后面就可以用HTTP/2通信了

- 问题

  - **精灵图（Spriting）、资源内联（inlining）、域名分片（Sharding）这些手段为什么会对 HTTP/2 的性能优化造成反效果呢？**
    - 精灵图，小图合成大图，客户端再用JS拆分，目的也是减少请求数。
    - 资源内联是对小资源如图片，js脚本进行base64编码，然后以文本形式嵌入到其它资源，目的是减少HTTP请求的数量。
    - 上述精灵图，资源内联，都是试图减少请求数，把资源合并到一个大请求中，对于HTTP/2请求数量不是问题。但上述方案，在小资源发生变化时，需要重传全部资源，原缓存将不得不更新，对HTTP/2而言得不偿失。
    - 域名分片会创建额外的连接，额外的连接增加了开销，对于HTTP/2没有必要，HTTP/2直接用流对应连接效率更高。

  











## 六.探索篇

### 1.WAF：保护我们的网络服务

#### 1.1 针对Web的攻击技术

- HTTP协议本身并不存在安全性问题，几乎不会成为攻击的对象。应用HTTP协议的服务器和客户端，以及运行在服务器上的Web应用等资源才是攻击目标。	

  - 目前来自互联网的攻击大多数把Web应用作为攻击目标

- 在客户端即可篡改请求

  - 在Web应用中，从浏览器收到的HTTP请求的内容都可以被自由变更和篡改。
    - 所以**Web应用可能会接受到与预期数据不相同的内容**
  - 在HTTP请求报文内加载攻击代码，就能对Web应用发起攻击
  - 通过URL查询字段或表单、HTTP首部、Cookie等途径把攻击代码传入，若这时Web应用存在安全漏洞，那内部信息就会遭到窃取，或被攻击者拿到管理权限

- 针对Web应用的攻击模式

  - 对Web应用的攻击模式有以下两种

    - 主动攻击
    - 被动攻击

  - **以服务器为目标的主动攻击**

    - **主动攻击是指攻击者通过直接访问Web应用，把攻击代码传入的攻击模式**
    - 由于该模式是直接针对服务器上的资源进行攻击的，因此攻击者需要能够访问到那些资源
    - **主动攻击模式中具有代表性的攻击是SQL注入攻击和OS命令注入攻击**

  - **以服务器为目标的被动攻击**

    - **被动攻击是指利用圈套策略执行攻击代码的攻击模式**

      - 在被动攻击中，攻击者不直接对目标Web应用访问发起攻击

    - 被动攻击的攻击模式：

      - 攻击者诱使用户触发已设置好的陷阱，而**陷阱会启动发送已嵌入攻击代码的HTTP请求**
      - 当用户中招之后，用户的浏览器或邮件客户端就会触发这个陷阱
      - **中招的用户浏览器会把含有攻击代码 的HTTP请求发送给作为攻击目标的Web应用，运行攻击代码**
      - 执行完攻击代码，存在安全漏洞的Web应用会成为攻击者的跳板，**可能导致用户所持的Cookie等个人信息被窃取，登录状态中的用户权限遭恶意滥用**等后果

    - 被动攻击模式中具有代表性的攻击是跨站脚本攻击和跨站点请求伪造

    - 利用被动攻击，可以发起对原本从互联网上无法直接访问的企业内网等网络的攻击

      

  



#### 1.2 因输出值转义不完全引发的安全漏洞

- 实施Web应用的安全对策可大致分为以下两部分：
  - 客户端的验证
    - 多数情况下采用JavaScript在客户端验证数据，但这只是起到提高UI体验的作用
  - Web应用端（服务器端）的验证
    - 输入值验证
      - 输入值验证通常是指检查是否符合系统业务逻辑的数值或检查字符编码等预防对策
    - 输出值转义
      - 从数据库或文件系统、HTML、邮件等输出Web应用处理的数据时，**针对输出值做转义处理是一项至关重要的安全策略**
      - 当输出值转义不完全时，会因触发攻击者传入的攻击代码而给输出对象带来损害



##### 1.2.1 跨站脚本攻击（XSS）

- **跨站脚本攻击是指通过存在安全漏洞的Web网站注册用户的浏览器内运行非法的HTML标签或JavaScript进行的一种攻击**

- 跨站脚本攻击有可能造成以下影响：

  - 利用虚假输入表单骗取用户个人信息
  - 利用脚本窃取用户的Cookie值，被害者在不知情的情况下，帮助攻击者发送恶意请求
  - 显示伪造的文章或图片

- 在动态生成HTML处发生

  - 比如在显示个人信息时，个人信息填上`<s>小明</s>`，这样如果代码没有做判断的话，会导致显示出来的是:~~小明~~

- **XSS是攻击者利用预先设置的陷阱触发的被动攻击**

  - **跨站脚本攻击(XSS)**属于被动攻击模式，因此攻击者会事先布置好用于攻击的陷阱

  - 它属于**"JS代码注入"**，利用JavaScript脚本获取未设防的Cookie

  - 进行XSS攻击：

    ```js
    1、假设有一个博客网站，我发表一篇博客，其中嵌入<script>脚本
    
    2、脚本内容：获取cookie 发送到我的服务器（服务器配合跨域）
    
    3、发布这篇文章，有人查看它，我轻松收割访问者的cookie
    
    4、可以通过 <script>document.cookie</script> 
    获取到当前域名的cookie，然后发送给攻击者的服务器，攻击者的服务器提前设置好允许跨域。
    ```

- **XSS的分类：**

  - 反射型XSS（非持久型XSS）：通过URL参数直接注入
    - 临时通过url访问网站，网站服务端将恶意代码从url中取出，拼接在HTML中返回给浏览器，用户就会执行恶意代码
    - ![src=http_%2F%2Fimg2020.cnblogs.com%2Fblog%2F2124308%2F202012%2F2124308-20201224130206411-694155369.png&refer=http_%2F%2Fimg2020.cnblogs.jpg](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ca090bf4747f462ea80cb02194b4baec~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image?)
  - 存储型XSS（持久型XSS）：存储到数据库后读取时注入
    - 将恶意代码以留言的形式保存在服务器数据库，任何访问网站的人都会受到攻击

- **XSS的危害：**

  - 获取cookie：网站中的登录一般都是用cookie作为某个用户的身份证明，这是服务器端返回的一串字符。如果cookie被攻击者拿到，那么就可以绕过密码登录。当空间、论坛如果可以被插入script代码，那么进入空间或者论坛的人的账号就可以轻易被攻击者获取。
  - 恶意跳转：直接在页面中插入window.location.href进行跳转。

- **预防XSS攻击的方案：**

  - 浏览器的防御和"X-XSS-Protection"有关，默认值为1，即默认打开XSS防御，可以防御反射型XSS，不过作用有限，只能防御注入到HTML的节点内容或属性的XSS，例如URL参数中包含script标签。不建议只依赖此防御手段

  - 替换特殊字符，如 < 变为`&It`; > 变为`&gt;`

    - `<script>`变为`&It; script &gt`; ,直接显示，而不会作为脚本执行

    - 替换的操作谁来做比较合适呢？前后端都可以，最好是前后都做，安全性更高

    - 前端可以通过正则匹配替换< >

  - 预防JavaScript代码，通过将数据进行JSON序列化。

  - 防御富文本是比较复杂的工程，因为富文本可以包含HTML和script，这些难以预测与防御，建议是通过白名单的方式来过滤允许的HTML标签和标签的属性来进行防御，大概的实现方式是：

    - 将HTML代码段转成树级结构的数据 - 遍历树的每一个节点，过滤节点的类型和属性，或进行特殊处理

    - 处理完成后，将树级结构转化成HTML代码 - 开启浏览器XSS防御：Http Only cookie，禁止 JavaScript 读取某些敏感 Cookie，攻击者完成XSS注入后也无法窃取此 Cookie。





##### 1.2.2 SQL注入攻击

- **SQL注入是指针对Web应用使用的数据库，通过运行非法的SQL而产生的攻击**。
- Web应用通常都会用到数据库，当需要操作数据库中数据时，会使用SQL语句连接数据库进行操作
  - 如果在调用SQL语句的方式上存在疏漏，就有可能执行被恶意注入非法SQL语句
- SQL注入攻击可能会造成以下等影响：
  - 非法查看或篡改数据库内的数据
  - 规避认证
  - 执行和数据库服务器业务关联的程序等
- **SQL注入攻击例子：**
  - 用户输入的用户名：Kite OR '1 = 1'--
    用户输入的密码：123456
  - 预想执行的SQL语句：`SELECT * FROM user WHERE username='Kite' AND psw='123456'`
  -  实际执行的SQL语句：`SELECT * FROM user WHERE username='Kite' OR 1 = 1 --' AND psw='xxxx'`
  - "--":是SQL的注释代码。也就是说 1 = 1 后面的代码无效。 结果就变成无论输入的用户名和密码是否正确，都可以登录。因为 1 = 1 肯定是为 true 。
- **如何防止SQL注入**
  - 通过正则验证用户输入的内容是否包含引起隐患的字符
  - 确认每种数据的类型，比如是数字，数据库则必须使用int类型来存储
  -  规定数据长度，能在一定程度上防止sql注入
  - 严格限制数据库权限，能最大程度减少sql注入的危害
  - 避免直接响应一些sql异常信息，sql发生异常后，自定义异常进行响应
  - 过滤参数中含有的一些数据库关键词





##### 1.2.3 OS命令注入攻击

- **OS命令注入攻击（OS Command Injection）是指通过Web应用，执行非法的操作系统命令达到攻击的目的**。
  - 只要在能调用Shell函数的地方就有存在被攻击的风险
- OS命令注入攻击可以向Shell发送命令，让Windows或Linux操作系统的命令行启动程序。
  - 也就是说，通过OS注入攻击可执行OS上安装着的各种程序





##### 1.2.4 HTTP首部注入攻击

- **HTTP首部注入攻击（HTTP Header Injection）是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。**

  - 属于被动攻击模式

- **向首部主体内添加内容的攻击成为HTTP响应截断攻击**

  - Web应用有时会把从外部接收到的数值赋给响应首部字段Location和Set-Cookie
  - HTTP首部注入可能像这样通过在某些响应首部字段需要处理输出值的地方，**插入换行发动攻击**

- **HTTP首部注入攻击的影响:**

  - 设置任何Cookie信息
  - 重定向至任意URL
  - 显示任意的主体（HTTP响应截断攻击）

- **HTTP首部注入攻击案例**

  - 比如Web应用接收到一个ID，就会将该ID放入Location首部中

    - 正常情况下是这样的：`Location:http://example.com/?cat=101`
    - 攻击者修改ID值为:`101%0D%0ASet-Cookie:+SID=123456789`
      - 其中`%0D%0A`代表HTTP报文中的换行符
      - 紧接着的是可强制将攻击者网站（`http://hackr.jp/`)的会话ID设置成SID=123456789的Set-Cookie字段

  - 发送该请求之后，假设结果返回以下响应：

    - ```js
      Location:http;//example.com/?cat=101 (%0D%0A ：换行符)
      Set-Cookie: SID=123456789
      ```

    - 此刻，首部字段Set-Cookie已生效，因此**攻击者可以指定修改任意的Cookie信息**

    - 通过和会话固定攻击（攻击者可使用指定的会话ID）攻击组合，攻击者可伪装成客户

    - **攻击者输入的%0D%0A，原本属于Location的查询值字段，但经过解析后，%0D%0A变成了换行符，结果插入了新的首部字段。这样一来，攻击者可在响应中插入任意的首部字段**

- **HTTP响应截断攻击**

  - HTTP响应截断攻击是用在HTTP首部注入的一种攻击
    - 攻击顺序相同，但是要将两个`%0D%0A%0D%0A`并排插入字符串后发送
    - 利用**两个连续的换行就可做出HTTP首部与主体分割所需的空行了，这样就能显示伪造的主体，达到攻击的目的**
  - 利用这个攻击，**已触发陷阱的用户浏览器会显示伪造的Web页面，再让用户输入自己的个人信息等，可达到和跨站脚本攻击相同的效果**

- 另外，**滥用HTTP/1.1中汇集多响应返回功能，会导致缓存服务器对任意内容进行缓存操作**

  - 这种攻击称为**缓存污染**
  - 使用该缓存服务器的用户，在浏览遭受攻击的网站时，会不断地浏览被替换掉的Web网页







##### 1.2.5 邮件首部注入攻击

- **邮件首部注入（Mail Header Injection）是指Web应用中的邮件发送功能，攻击者通过邮件首部To或Subject内任意添加非法内容发起的攻击**。
  - 利用存在安全漏洞的Web网站，可对任意邮件地址发送广告邮件或病毒邮件
- 原理跟HTTP首部注入攻击相同





##### 1.2.6 目录遍历攻击

- **目录遍历攻击是指对本无意公开的文件目录，通过非法截断其目录路径后，达成访问目的的一种攻击。**

  - 这种攻击有时也称为**路径遍历攻击**
  - 通过Web应用对文件处理操作时，在由外部指定文件名的处理存在疏漏的情况下，用户可使用.../等相对路径定位到/etc/passed等绝对路径上，因此服务器上任意的文件或文件目录皆有可能被访问到。这样一来，就有可能非法浏览、篡改或删除Web服务器上的文件

- **目录遍历攻击案例**

  - 正常情况下，通过`http://example.com/read.php?log=0401.log`读取到这个指定的文件

  - 攻击者设置如下查询字段后发出请求：`http://example.com/read.php?log=../../etc/passwd`

    - 查询字段为了读取攻击者盯上的`/etc/passwd`文件，会从`/www/log/`目录开始定位相对路径。
    - 如果这份read.php脚本接受对指定目录的访问请求处理，那原本不公开的文件就存在可被访问的风险

    





##### 1.2.7 远程文件包含漏洞

- **远程文件包含漏洞是指当部分脚本内容需要从其他文件读入时，攻击者利用指定外部服务器的URL充当依赖文件，让脚本读取之后，就可运行任意脚本的一种攻击**

- 这主要是PHP存在的安全漏洞

  



#### 1.3 因设置或设计上的缺陷引发的安全漏洞

- 因设置或设计上的缺陷引发的安全漏洞是指：**错误设置Web服务器，或是由设计上的一些问题引起的安全漏洞**



##### 1.3.1 强制浏览

- **强制浏览安全漏洞是指：从安置在Web服务器的公开目录下的文件中，浏览那些原本非资源公开的文件**
- 强制浏览会造成的影响：
  - 泄露顾客的个人信息等重要情报
  - 泄露原本需要具有访问权限的用户才可查阅的信息内容
  - 泄露未外连到外界的文件
- 对原本不愿公开的文件，为了保证安全会**隐蔽其URL**。但一旦知道了URL，也就意味着可以浏览URL对应的文件。直接显示**容易推测**的文件名或文件目录索引时，通过某些方法可能会使URL产生泄露
  - **文件目录一览**
    - 通过指定文件目录名称，即可在文件一览中看到显示的文件名
  - **容易被推测的文件名及目录名**
    - `http://www.example.com/entry/entry_081202.log`
    - 文件名称容易推测（按照上面的情况，可以推断出下一个文件可能是`entry_081203.log`
  - **备份文件**
    - `http://www.example.com/cgi-bin/entry.cgi`(原始文件)
    - `http://www.example.com/cgi-bin/entry.cgi~`(备份文件)
    - `http://www.example.com/cgi-bin/entry.bak`(备份文件)
    - 由编辑软件自动生成的备份文件无执行权限，有可能直接以源代码形式展示
  - **经认证才可显示的文件**
    - 直接通过URL访问原本必须经过认证才能在Web页面上使用的文件





##### 1.3.2 不正确的错误消息处理

- **不正确的错误消息处理的安全漏洞是指：Web应用的错误信息内包含对攻击者有用的信息**
- 与Web应用有关的主要错误信息为：
  - Web应用抛出的错误消息
  - 数据库等系统抛出的错误消息
- 不正确的错误消息处理导致安全漏洞的案例
  - 有一个登录功能，需要输入邮箱地址和密码
    - 当输入的邮箱地址尚未在该网站注册时，会弹出"邮箱地址未注册"
    - 若邮件地址存在，密码错误时，会弹出"输入的密码有误"
  - 攻击者利用不同的输入会提示不同的错误信息这条，就可以用来确认输入的邮件地址是否已在这个网站上注册过了
  - 为了不让错误消息给攻击者启发，建议将提示消息仅保留"认证错误"即可





##### 1.3.3 开放重定向

- **开放重定向是一种对指定的任意URL作重定向跳转的功能。而与此功能相关联的安全漏洞是指：假如指定的重定向URL到某个具有恶意的Web网站，那么用户就会被诱导至那个Web网站**

  









#### 1.4 因会话管理疏忽引发的安全漏洞

- 会话管理是用来管理用户状态的必备功能，但是如果在会话管理上有所疏忽，就会**导致用户的认证状态被窃取等后果**



##### 1.4.1 会话劫持

- **会话劫持是指攻击者通过某种手段拿到了用户的会话ID，并非法使用此会话ID伪装成客户，达到攻击的目的**
- 攻击者可获得会话ID的途径
  - 通过非正规的生成方法推测会话ID
  - 通过窃听会XSS攻击盗取会话ID
  - 通过会话固定攻击(Session Fixation)强行获取会话ID
- **攻击案例**
  - 攻击者在得知该网站存在可跨站攻击（XSS）的安全漏洞后，设置好JavaScript脚本调用document.cookie以窃取Cookie信息的陷阱，一旦用户踏入陷阱（访问了该脚本），攻击者就能获取含有会话ID的Cookie
  - 攻击者拿到用户的会话ID后，往自己浏览器的Cookie中设置该会话ID，即可伪装成会话ID遭窃的用户访问该网站了





##### 1.4.2 会话固定攻击

- **对以窃取目标会话ID为主动攻击手段的会话劫持而言，会话固定攻击会强制用户使用攻击者指定的会话ID，属于被动攻击**
- **攻击案例**
  - 设定：当前网站会在访问时（认证前）发布一个会话ID，若认证成功，就会在服务器内改变认证状态
  - 攻击者准备陷阱，先访问Web网站拿到**未认证的会话ID**
  - 然后攻击者设置好强制用户使用该会话ID的陷阱，并等待用户拿着这个会话ID去认证
    - 一旦用户触发陷阱并完成认证，会话ID在服务器上的状态（用户已认证）就会被记录下来
  - 攻击者估计用户差不多已经触发陷阱后，再利用之前这个会话ID访问网站
    - 由于该会话ID目前已是（用户已认证）状态，于是攻击者作为用户的身份顺利登录网站

- **Session Adoption**
  - Session Adoption是指PHP或ASP.NET能够接受处理未知会话ID的功能
  - 恶意使用该功能便可**跳过会话固定攻击的准备阶段**，从Web网站获得发行的会话ID的步骤。
  - 即**攻击者可私自创建会话ID构成陷阱，中间件却会误以为该会话ID是未知会话ID而接受**







##### 1.4.3 跨站点请求伪造（CSRF）

- **跨站点请求伪造（Cross-Site Request Forgeries，CSRF）攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击**

- 跨站点请求伪造会造成的影响：

  - 利用已通过认证的用户权限更新设定信息等
  - 利用已通过认证的用户权限购买商品
  - 利用已通过认证的用户权限在留言板上发表言论

- **攻击案例**

  - 设定：有一个留言板，只允许已认证并登陆的用户在留言板上发表内容

  - 在该留言板系统上，受害者A是已认证状态。它的浏览器中的Cookie持有已认证的会话ID

  - 攻击者**设置一旦用户访问，即会在留言板上发表 带有攻击者言论 的陷阱。**用户A的浏览器执行完陷阱中的请求后，留言板上就会留下攻击者的言论

  - 陷阱触发时，如果用户A还没通过认证，则无法利用用户A的身份权限在留言板上留言

    



#### 1.5 其他安全漏洞

##### 1.5.1 密码破解

- **密码破解攻击即算出密码，突破认证**
  - 攻击不仅限于Web应用，还包括其他的系统（如FTP或SSH等）
- **密码破解的手段**
  - 通过网络的密码试错
  - 对已加密密码的破解（指攻击者入侵系统，已获得加密或散列处理的密码数据的情况）
- **通过网络进行密码试错**
  - **是对Web应用提供的认证功能，通过网络尝试候选密码进行的一种攻击**
  - 主要有以下两种方式：
    - 穷举法
    - 字典攻击
  - 穷举法
    - **穷举法（Brute-force Attack，又称暴力破解法）是指对所有密钥集合构成的密钥空间进行穷举**
      - 即用所有可行的候选密码对目标的密码系统试错，用以突破验证
  - 字典攻击
    - **字典攻击是指利用事先收集好的候选密码（经过各种组合方式后存入字典），枚举字典中的密码，尝试通过认证的一种攻击方法**
    - 例如：
      - 某银行采用的个人识别码是由"4位数字"组成的密码，考虑到用户使用自己的生日作为密码的可能性较高，于是就可以将0101~1231保存成字典，进行尝试
    - **使用字典可缩短得到正确密码的时间，但如果密码不在字典中就无法正确匹配**
    - **利用别处泄露的ID和密码进行攻击**
      - 字典攻击中有一种利用其他Web网站已泄露的ID及密码列表进行的攻击
      - 很多用户习惯随意地在多个Web网站使用同一套ID和密码，因此攻击会有相当高的几率

- **对已加密密码的破解**
  - Web应用在保存密码时，通常不会直接以明文的方式保存，通过散列函数作散列处理或加salt的手段对要保存的密码本身加密。那即使攻击者使用某些手段窃取到密码，还需要**通过解码等手段，把加密处理的密码还原成明文形式**
  - **从加密过的数据中导出明文的方法**
    - 通过穷举法、字典攻击进行类推
    - 彩虹表
    - 拿到密钥
    - 加密算法的漏洞
  - **通过穷举法、字典攻击进行类推**
    - 针对密码使用散列函数进行加密的情况，**采用和穷举法或字典攻击相同的收发，尝试调用相同的散列函数加密候选密码，然后把计算出的散列值与目标散列值匹配，类推出密码**
  - **彩虹表**
    - **彩虹表是由明文密码及与之对应的散列值构成的一张数据库表，是一种通过实现制作庞大的彩虹表，可在穷举法、字典攻击等实际破解过程中缩短消耗时间的技巧**
      - 从彩虹表内搜索散列值就可以推导出对应的明文密码
  - **拿到密钥**
    - 使用共享密钥加密方式对密码数据进行加密处理的情况下，如果能够通过某种手段拿到加密使用的密钥，也就可以对密码数据解密了





##### 1.5.2 点击劫持

- **点击劫持是指利用透明的按钮或链接做成陷阱，覆盖在Web页面之上。然后诱使用户在不知情的情况下，点击那个链接访问内容的一种攻击手段。**
  - 这种行为又称为界面伪装（UI Redressing）





##### 1.5.3 DoS攻击

- **DoS攻击是一种让运行中的服务呈停止状态的攻击。**
  - 有时也叫做服务停止攻击或拒绝服务攻击
  - DoS攻击的对象不仅限于Web网站，还包括网络设备及服务区等
- **主要有以下两种DoS攻击方式**
  - 集中利用访问请求造成资源过载，资源用尽的同时，实际上服务也就呈停止状态
  - 通过攻击安全漏洞使服务停止
- 其中，**集中利用访问请求的DoS攻击，单纯来讲就是发送大量的合法请求**
  - 服务器很难分辨何为正常请求，何为攻击请求，因此很难防止DoS攻击
- **多台计算机发起的DoS攻击称为DDoS攻击**
  - DDoS攻击通常利用那些感染病毒的计算机作为攻击者的攻击跳板





##### 1.5.4 后门程序

- **后门程序是指开发设置的隐藏入口，可不按正常步骤使用受限功能**
  - 利用后门程序就能够使用原本受限制的功能
- 通常的后门程序分为以下3种类型：
  - 开发阶段作为Debug调用的后门程序
  - 开发者为了自身利益植入的后门程序
  - 攻击者通过某种手段设置的后门程序









#### 1.6 网络应用防火墙（WAF）

- 面对这么多的黑客攻击手段，我们用到的防御方法就是"**网络应用防火墙**"(Web Application Firewall)，简称"**WAF**"

- WAF工作在七层，看到的不仅是IP地址和端口号，还能看到整个HTTP报文，所以就能够对报文内容做更深入细致的审核，使用更复杂的条件、规则来过滤数据
  - WAF就是一种"**HTTP入侵检测和防御系统**"
  - ![image-20221107221503685](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221107221503685.png)
- 一款产品要能够称为WAF，需要具备的功能有：
  - IP黑名单和白名单，拒绝黑名单上地址的访问，或者只允许白名单上的用户访问
  - URI黑名单和白名单，与IP黑白名单相似，允许或禁止对某些URI的访问
  - 防护DDoS攻击，对特定的IP地址限连限速
  - 过滤请求报文，防御"代码注入"攻击
  - 过滤响应报文，防御敏感信息外泄
  - 审计日志，记录所有检测到的入侵操作











### 2.CDN：加速我们的网络服务

- 在外部加速HTTP协议的服务：**CDN（Content Delivery Network 或 Content Distribution Network），中文名叫"内容分发网络"**

#### 2.1 什么是CDN

- CDN是**专门为解决"长距离"上网络访问速度慢而诞生的一种网络应用服务**
- 从名字上看，CDN有三个关键词：**“内容”、“分发”、“网络”**
- **CDN的最核心原则就是"就近访问"**
  - 如果用户能够在本地几十公里的距离之内获取到数据，那么时延基本上变成0了
  - 所以CDN投入大量资金，在全国乃至全球的各大枢纽城市都建立了机房，**部署了大量拥有高存储高带宽的结点，构建了一个专用网络**
  - 有了这个高速的专用网之后，CDN就要"分发"源站的"内容"了。利用**缓存代理**技术，把源站的内容逐级缓存到网络的每一个结点上
  - 于是，用户在上网的时候就不直接访问源站，而是访问离他最近的一个CDN结点，术语叫"**边缘节点**"，其实就是缓存了源站内容的代理服务区。这样就实现了"网络加速"
- CDN能加速的“资源”
  - 分为**静态资源**和**动态资源**
  - 静态资源是指数据内容"静态不变"，**任何时候来访问都是一样的，比如图片、音频。**
  - 动态资源是指**数据内容是"动态变化"的，也就是由后台服务计算生成的，每次访问都不一样**。比如商品的库存、微博的粉丝数等







#### 2.2 **CDN的负载均衡**

- CDN由两个关键组成部分：**全局负载均衡**和**缓存系统**
- **全局负载均衡**
  - 一般简称为**GSLB**，它是CDN的大脑，主要的**职责是当用户接入网络的时候在CDN专网中挑选出一个"最佳"结点提供服务**。
  - 解决的是用户如何找到"最近的"边缘结点，对整个CDN网络进行"负载均衡"
  - GSLB最常见的实现方式是"**DNS负载均衡**"
    - 在原来**没有CDN的时候，权威DNS返回的是网站自己服务器的实际IP地址**，浏览器收到DNS解析结果后直连网站
    - **加入CDN后，权威DNS返回的部署IP地址，而是一个CNAME（Canonical Name）别名记录，指向的就是CDN的GSLB**。
    - 因为没拿到IP地址，于是本地DNS就会像GSLB再发起请求，这样就进入了CDN的全局负载均衡系统，开始"智能调度"，主要的依据有：
      1. 看用户的IP地址，查表得知地理位置，找相对最近的边缘节点
      2. 看用户所在的运营商网络，找相同网络的边缘节点
      3. 检查边缘节点的负载情况，找负载较轻的节点
      4. 其他，比如节点的"健康状况"、服务能力、带宽、响应时间等
    - GSLB把这些因素综合起来，用一个复杂的算法，最后找出一台"最合适"的边缘节点，把这个节点的IP地址返回给用户，用户就可以"就近"访问CDN的缓存代理了







#### 2.3 **CDN的缓存代理**

- 缓存系统相对于CDN的"心脏"。如果缓存系统的服务能力不够，那就算GSLB调度算法再优秀也没用
- 有两个关键概念：**命中**和**回源**
  - **命中就是指用户访问的资源恰好再缓存系统里，可以直接返回给用户**
  - **回源就是缓存里没有，必须用代理的方式回源站取**
- 也就有了两个**衡量CDN服务质量的指标**："**命中率**"和”**回源率**“
  - **命中率就是命中次数与所有访问次数之比**
  - **回源率就算回源次数与所有访问次数之比**
  - **好的CDN应该是命中率越高越好，回源率越低越好**
- 如何提高命中率、降低回源率？
  1. 再存储系统上升级硬件，软件系统更新
  2. 缓存系统划分出层次，分成一级缓存节点和二级缓存节点
     - ·一级缓存配置高一点，直连源站
     - 二级缓存配置低一点，直连用户
     - 回源的时候二级只找一级，一级没有才回源站。这样最终**"扇入度"就缩小了**，可以有效减少真正的回源
  3. 使用高性能的缓存服务











### 3.WebSocket：沙盒里的TCP

#### 3.1 为什么要有WebSocket

- **WebSocket是一种基于TCP的轻量级网络通信协议，在地位上与HTTP平级**

  - WebSocket与HTTP/2一样，都是为了解决HTTP某方面的缺陷而诞生的。
  - HTTP/2针对的是"队头阻塞"，而**WebSocket针对的是"请求-应答"通信模式**

- "请求-应答"模式有什么不好的地方？

  - "请求-应答"是一种"**半双工**"的通信模式，虽然可以双向收发数据，但**同一时刻只能一个方向上有动作，传输效率低**。
  - **它是一种"被动"通信模式，服务器只能"被动"响应客户端的请求，无法主动向客户端发送数据**
  - 这就导致HTTP难以应用在动态页面、即时消息、网络游戏等要"**实时通信**"的领域

- 在WebSocket出现之前，在浏览器环境里开发实时Web应用常用的方法是"**轮询**"

  - **轮询就算不停向服务器发送HTTP请求，问有没有数据，有数据的话服务器就用响应报文回应。**如果轮询的频率比较高，那么就可以近似地实现"实时通信"的效果
  - 轮询的缺点：**反复发送无效查询请求耗费了大量的带宽和CPU资源，非常不经济**

- JavaScript可调用"The WebSocket API"（http://www.w3.org/TR/websockets/)内提供的WebSocket程序接口，以实现WebSocket协议下全双工通信

  - 例：每50ms发送一次数据的实例

    ```js
    var socket = new WebSocket('ws://game.example.com:12010/updates');
    socket.onopen = function() {
        setInterval(funciton() {
               if(socket.bufferedAmount == 0) 
        			socket.send(getUpdateData());
        },50);
    };
    ```





#### 3.2 WebSocket的特点

- **WebSocket是一个真正"全双工"的通信协议**。与TCP一样，客户端和服务器都可以随时向对方发送数据
  - 于是，服务器就可以一旦有了新的数据，就将其推送给客户端，而不需要客户端轮询，"实时通信"的效率也就提高了
- **WebSocket采用了二进制帧结构，语法、语义与HTTP完全不兼容，但因为它的主要运行环境是浏览器，于是它在使用习惯上尽量向HTTP靠拢**
- **只要建立起WebSocket连接，就希望一直保持连接状态**
- **WebSocket没有使用TCP的"IP地址+端口号"，而是延用了HTTP的URI格式，但开头的协议名不是"http"，引入的是两个新的名字：<u>"ws"和"wss"</u>，<u>分别表示明文和加密的WebSocket协议</u>**
- **WebSocket的默认端口也选择了80和443，因为现在互联网上的防火墙屏蔽了大多数的端口，只对HTTP的80、443端口放行**





#### 3.3 WebSocket的帧结构

- WebSocket虽然有”帧“，但却没有定义HTTP/2那样的"流"，也就不存在"多路复用"、"优先级"等特性
- ![image-20221108195240193](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221108195240193.png)
- **开头两个字节是必须的，也是最关键的**
- 第一个字节的第一位"**FIN**"是**消息结束的标志位**，相当于HTTP/2里的"END_STREAM"，**表示数据发送完毕**
  - 一个消息可以拆成多个帧，接收方看到"FIN"后，就可以把前面的帧拼起来，组成完整的消息
  - "FIN"后面的三个位是保留位，目前没有任何意义，**但必须是0**
- 第一个字节的后4位很重要，叫"**Opcode**"，**操作码，其实就是帧类型**
  - 比如1表示帧文本是纯文本
  - 2表示帧内容是二进制数据
  - 8是关闭连接
  - 9和10分别是连接保活的PING和PONG
- 第二个字节第一位是**掩码标志位"MASK"，表示帧内容是否使用异或操作（xor）做简单的加密**
  - 目前的WebSocket规定，客户端发送数据必须使用掩码，而服务器发送则必须不使用掩码
- 第二个字节后7位是"**Payload len**"，**表示帧内容的长度**。它是另一种变长编码，最少7位，最多是7+64位，也就是额外增加8个字节，所以一个WebSocket帧最大是2^64^
  - 长度字段后面是"**Masking-key**"，**掩码密钥，它是由上面的标志位"MASK"决定的，如果使用掩码是4个字节的随机数，否则就不存在**
- 其实WebSocket的帧头就四个部分："**结束标志位+操作码+帧长度+掩码"**







#### 3.4 WebSocket的握手

- 和TCP、TLS一样，WebSocket也要有一个握手过程，然后才能正式收发数据
  - WebSocket利用了HTTP本身的"协议升级"特性，“伪装“成HTTP，这样就能绕过浏览器沙盒、网络防火墙等限制，这也是WebSocket与HTTP的另一个重要关联点
- **WebSocket的握手是一个标准的HTTP GET请求**，但要**带上两个协议升级的专用头字段**：
  - `Connection:Upgrade`：表示要求协议"升级"
  - `Upgrade:websocket`：表示要"升级"成WebSocket协议

- 另外，**为了防止普通的HTTP消息被"意外"识别成WebSocket，握手消息还增加了两个额外的认证用头字段**（所谓的"挑战"，Challenge）：

  - `Sec-WebSocket-Key`：一个Base64编码的16字节随机数，作为简单的认证密钥
  - `Sec-WebSocket-Version`：协议的版本号，当前必须是13
  - ![image-20221108200946473](C:\Users\ZZY\AppData\Roaming\Typora\typora-user-images\image-20221108200946473.png)

- 服务器收到HTTP请求报文，看到上面的四个字段，就知道这不是一个普通的GET请求，而是WebSocket的升级请求。于是就不走普通的HTTP处理流程，而是**构造一个特殊的"101 Switching Protocols"响应报文，通知客户端，接下来就不用HTTP了，全改用WebSocket协议通信**

- **WebSocket的握手响应报文也是有特殊格式的，要用字段`Sec-WebSocket-Accept`验证客户端请求报文，同样也是为了防止误连接**

  - 具体是做法是**把请求头里"Sec-WebSocket-Key"的值，加上一个专用的UUID"258EAFA5-E914-47DA-95CA-C5AB0DC85B11"，在计算SHA-1摘要**

- 客户端收到响应报文，可以用同样的算法，比对值是否相等，如果相等，就说明返回的报文确实是刚才握手时连接的服务器，认证成功

- 握手完成，后续传输的数据就不再是HTTP报文，而是WebSocket格式的二进制帧了

  
